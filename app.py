import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re
import numpy as np
import librosa

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def create_silence(duration_seconds, sample_rate=24000):
    """Táº¡o Ä‘oáº¡n im láº·ng vá»›i thá»i gian xÃ¡c Ä‘á»‹nh."""
    num_samples = int(duration_seconds * sample_rate)
    return np.zeros(num_samples, dtype=np.float32)

def detect_sentence_boundaries(text):
    """
    PhÃ¡t hiá»‡n vá»‹ trÃ­ cÃ¡c cÃ¢u vÃ  loáº¡i (paragraph/dialogue).
    Returns: list of (position, pause_type)
        position: vá»‹ trÃ­ kÃ½ tá»± káº¿t thÃºc cÃ¢u trong text
        pause_type: 'paragraph' hoáº·c 'dialogue'
    """
    boundaries = []
    paragraphs = text.split('\n\n')
    current_pos = 0
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            current_pos += 2  # \n\n
            continue
        
        # Kiá»ƒm tra xem Ä‘oáº¡n nÃ y cÃ³ pháº£i há»™i thoáº¡i khÃ´ng
        lines = para.split('\n')
        combined_text = ' '.join(line.strip() for line in lines if line.strip())
        
        has_quotes = '"' in combined_text or '"' in combined_text or '"' in combined_text
        is_dialogue = has_quotes
        pause_type = 'dialogue' if is_dialogue else 'paragraph'
        
        # TÃ¬m cÃ¡c dáº¥u cÃ¢u káº¿t thÃºc trong Ä‘oáº¡n nÃ y
        for match in re.finditer(r'[.!?]+', combined_text):
            # Vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i trong toÃ n bá»™ text
            boundaries.append({
                'char_pos': current_pos + match.end(),
                'pause_type': pause_type
            })
        
        current_pos += len(para) + 2  # +2 cho \n\n
    
    return boundaries

def estimate_audio_position(text, char_pos, total_chars, total_audio_length):
    """
    Æ¯á»›c tÃ­nh vá»‹ trÃ­ trong audio tÆ°Æ¡ng á»©ng vá»›i vá»‹ trÃ­ kÃ½ tá»± trong text.
    Giáº£ Ä‘á»‹nh tá»‘c Ä‘á»™ Ä‘á»c tÆ°Æ¡ng Ä‘á»‘i Ä‘á»“ng Ä‘á»u.
    """
    ratio = char_pos / max(total_chars, 1)
    return int(ratio * total_audio_length)

def insert_pauses_into_audio(audio, sample_rate, text, pause_paragraph=0.8, pause_dialogue=0.4):
    """
    ChÃ¨n khoáº£ng im láº·ng vÃ o audio Ä‘Ã£ táº¡o dá»±a trÃªn vá»‹ trÃ­ cÃ¢u trong text.
    
    Args:
        audio: numpy array cá»§a audio Ä‘Ã£ táº¡o
        sample_rate: táº§n sá»‘ máº«u
        text: vÄƒn báº£n gá»‘c (Ä‘Ã£ processed)
        pause_paragraph: thá»i gian pause cho Ä‘oáº¡n vÄƒn (giÃ¢y)
        pause_dialogue: thá»i gian pause cho há»™i thoáº¡i (giÃ¢y)
    
    Returns:
        numpy array: audio vá»›i pause Ä‘Ã£ chÃ¨n
    """
    # PhÃ¡t hiá»‡n cÃ¡c vá»‹ trÃ­ cÃ¢u
    boundaries = detect_sentence_boundaries(text)
    
    if not boundaries:
        print("âš ï¸ No sentence boundaries detected, returning original audio")
        return audio
    
    print(f"\nðŸ” Detected {len(boundaries)} sentence boundaries:")
    for i, b in enumerate(boundaries[:5]):  # Show first 5
        print(f"   {i+1}. Char {b['char_pos']}: {b['pause_type']}")
    
    # Chuyá»ƒn Ä‘á»•i vá»‹ trÃ­ kÃ½ tá»± sang vá»‹ trÃ­ audio (samples)
    total_chars = len(text)
    total_samples = len(audio)
    
    pause_configs = {
        'paragraph': pause_paragraph,
        'dialogue': pause_dialogue
    }
    
    # Táº¡o danh sÃ¡ch cÃ¡c Ä‘oáº¡n audio cáº§n ghÃ©p
    segments = []
    last_pos = 0
    
    for boundary in boundaries:
        # Æ¯á»›c tÃ­nh vá»‹ trÃ­ trong audio
        char_pos = boundary['char_pos']
        audio_pos = estimate_audio_position(text, char_pos, total_chars, total_samples)
        
        # ThÃªm Ä‘oáº¡n audio tá»« vá»‹ trÃ­ cÅ© Ä‘áº¿n vá»‹ trÃ­ hiá»‡n táº¡i
        if audio_pos > last_pos and audio_pos <= total_samples:
            segments.append(audio[last_pos:audio_pos])
            
            # ThÃªm pause
            pause_duration = pause_configs[boundary['pause_type']]
            silence = create_silence(pause_duration, sample_rate)
            segments.append(silence)
            
            last_pos = audio_pos
    
    # ThÃªm pháº§n audio cÃ²n láº¡i
    if last_pos < total_samples:
        segments.append(audio[last_pos:])
    
    # GhÃ©p táº¥t cáº£ láº¡i
    final_audio = np.concatenate(segments) if segments else audio
    
    added_duration = (len(final_audio) - len(audio)) / sample_rate
    print(f"\nâ¸ï¸  Added {added_duration:.2f}s of pauses to audio")
    
    return final_audio

def post_process(text):
    """LÃ m sáº¡ch vÄƒn báº£n."""
    text = " " + text + " "
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = re.sub(r',+', ',', text)
    text = text.replace(" , ", " ")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    TTS inference - xá»­ lÃ½ toÃ n bá»™ vÄƒn báº£n má»™t láº§n, sau Ä‘Ã³ chÃ¨n pause.
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        print(f"\n{'='*60}")
        print(f"ðŸŽ¤ Starting TTS generation with post-processing pauses")
        print(f"{'='*60}")
        
        # Cáº¥u hÃ¬nh pause theo thá»i gian (giÃ¢y)
        pause_configs = {
            "Short": (0.4, 0.2),    # Paragraph: 0.4s, Dialogue: 0.2s
            "Medium": (0.8, 0.4),   # Paragraph: 0.8s, Dialogue: 0.4s
            "Long": (1.2, 0.6)      # Paragraph: 1.2s, Dialogue: 0.6s
        }
        
        pause_paragraph, pause_dialogue = pause_configs.get(pause_level, (0.8, 0.4))
        
        print(f"\nðŸŽ›ï¸ Pause config: Paragraph={pause_paragraph}s, Dialogue={pause_dialogue}s")
        
        # LÆ°u text gá»‘c Ä‘á»ƒ phÃ¡t hiá»‡n boundaries
        original_text = gen_text
        
        print(f"\nðŸ“Š Stats:")
        print(f"   Text length: {len(gen_text)} chars")
        print(f"   Word count: {len(gen_text.split())} words")
        
        # Preprocess reference audio
        print(f"\nðŸ”„ Processing reference audio...")
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        print(f"   Reference text: {ref_text[:100]}...")
        
        # Chuáº©n hÃ³a vÄƒn báº£n - KHÃ”NG thÃªm dots
        normalized_text = post_process(TTSnorm(gen_text)).lower()
        
        print(f"\nðŸ“ Normalized text preview:")
        print(f"   {normalized_text[:200]}...")
        
        # === BÆ¯á»šC 1: Táº¡o audio TOÃ€N Bá»˜ má»™t láº§n ===
        print(f"\nðŸŽµ Generating complete audio (single-pass)...")
        base_wave, sample_rate, spectrogram = infer_process(
            ref_audio, 
            ref_text.lower(), 
            normalized_text, 
            model, 
            vocoder, 
            speed=speed
        )
        
        base_duration = len(base_wave) / sample_rate
        print(f"   âœ… Base audio: {base_duration:.2f}s")
        
        # === BÆ¯á»šC 2: ChÃ¨n pause vÃ o Ä‘Ãºng vá»‹ trÃ­ ===
        print(f"\nâ¸ï¸  Inserting pauses at sentence boundaries...")
        final_wave = insert_pauses_into_audio(
            base_wave, 
            sample_rate, 
            original_text,  # DÃ¹ng text gá»‘c Ä‘á»ƒ detect boundaries
            pause_paragraph, 
            pause_dialogue
        )
        
        final_duration = len(final_wave) / sample_rate
        print(f"\nâœ… Final audio generated successfully!")
        print(f"   Base duration: {base_duration:.2f}s")
        print(f"   Final duration: {final_duration:.2f}s")
        print(f"   Added: {final_duration - base_duration:.2f}s")
        print(f"   Sample rate: {sample_rate}Hz")
        print(f"{'='*60}\n")
        
        # LÆ°u spectrogram (tá»« base audio)
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        return (sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ðŸŽ¤ F5-TTS: Vietnamese Text-to-Speech with Smart Pause Injection
    ### Model trained with ~1000 hours of data on RTX 3090 GPU
    
    **ðŸŽ¯ New Approach**: Generate full audio first, then inject silence at sentence boundaries!
    
    âœ¨ **Key Features**:
    - âœ… Reads **entire text at once** (including foreign language!)
    - âœ… Inserts **real silence** after generation
    - âœ… No sentence splitting = better continuity
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ðŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ðŸ“ Text to Generate", 
            placeholder="""Enter text with paragraphs and foreign words...

Example:
Háº¯n lÃºc nÃ y Ä‘ang ngá»“i trÃªn boong tÃ u. Máº¯t nhÃ¬n ra biá»ƒn xa.

"Toa láº§n nÃ y trá»Ÿ vá» nhÃ  chÆ¡i Ä‘Æ°á»£c bao lÃ¢u?"

NgÆ°á»i há»i lÃ  má»™t ngÆ°á»i báº¡n tÃ¬nh cá» gáº·p. "Merci beaucoup!"

ÄÃ¢y lÃ  cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ xá»­ lÃ½ multilingual text.""", 
            lines=10
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="âš¡ Speed"
        )
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Real silence duration inserted after generation"
        )
    
    btn_synthesize = gr.Button("ðŸ”¥ Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="ðŸŽ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ðŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ðŸ’¡ How It Works (2-Step Process):
    
    | Step | Process | Benefit |
    |------|---------|---------|
    | **1. Full Generation** | Model reads entire text at once | Foreign words handled perfectly |
    | **2. Pause Injection** | Insert silence at detected boundaries | Natural pauses without breaking flow |
    
    ### ðŸŽ¯ Algorithm:
    
    ```
    Input: "Háº¯n ngá»“i trÃªn tÃ u. Máº¯t nhÃ¬n biá»ƒn.\n\n\"Merci beaucoup!\""
    
    Step 1: Generate full audio (10 seconds)
    â”œâ”€â”€ Model reads: "háº¯n ngá»“i trÃªn tÃ u máº¯t nhÃ¬n biá»ƒn merci beaucoup"
    â””â”€â”€ Output: continuous audio stream
    
    Step 2: Detect boundaries in original text
    â”œâ”€â”€ Sentence 1 ends at char 23 (paragraph) â†’ audio position ~3s
    â”œâ”€â”€ Sentence 2 ends at char 42 (paragraph) â†’ audio position ~6s  
    â””â”€â”€ Sentence 3 ends at char 60 (dialogue) â†’ audio position ~9s
    
    Step 3: Insert pauses
    â”œâ”€â”€ Insert 0.8s silence at 3s mark
    â”œâ”€â”€ Insert 0.8s silence at 6s mark
    â””â”€â”€ Insert 0.4s silence at 9s mark
    
    Final: 10s + 2.0s = 12s audio with natural pauses
    ```
    
    ### ðŸ“– Pause Levels:
    
    | Level | Paragraph | Dialogue | Best For |
    |-------|-----------|----------|----------|
    | **Short** | 0.4s | 0.2s | News, fast reading |
    | **Medium** | 0.8s | 0.4s | Stories, natural speech |
    | **Long** | 1.2s | 0.6s | Audiobooks, dramatic reading |
    
    ### âœ… Advantages Over Previous Approaches:
    
    | Feature | Dots Method | Sentence Split | **This Method** |
    |---------|-------------|----------------|-----------------|
    | Foreign words | âš ï¸ May skip | âŒ Fails | âœ… Perfect |
    | Processing speed | âš¡ Fast | ðŸŒ Slow | âš¡ Fast |
    | Audio continuity | âœ… Good | âš ï¸ Fragmented | âœ… Excellent |
    | Pause precision | âš ï¸ Approximate | âœ… Exact | âœ… Exact |
    | No weird sounds | âš ï¸ Sometimes | âœ… Yes | âœ… Yes |
    
    ### ðŸ“ Usage Tips:
    - Separate major sections with **double line breaks** (`\\n\\n`)
    - Foreign words/phrases are handled naturally: `"Merci beaucoup!"`
    - Quotes indicate dialogue: `"Hello," she said.`
    - Model reads everything once, then pauses are added
    
    ### ðŸ”§ Technical Notes:
    - Pause positions estimated by character ratio: `audio_pos = (char_pos / total_chars) Ã— audio_length`
    - Paragraph detection: double line breaks (`\\n\\n`)
    - Dialogue detection: presence of quotation marks
    - Silence insertion: numpy zero arrays
    """)
    
    with gr.Accordion("â— Model Limitations & Troubleshooting", open=False):
        gr.Markdown("""
        ### Limitations:
        1. **Pause Estimation**: Position is estimated, not exact (based on uniform reading speed assumption)
        2. **Very Long Texts**: Texts over 1000 words may have timing drift
        3. **Uneven Reading Speed**: If model reads some parts faster, pause timing may be off
        4. **Numbers & Special Chars**: May not pronounce dates/phone numbers correctly
        
        ### Troubleshooting:
        - **Pauses in wrong places**: Text length estimation issue - try splitting long texts
        - **Foreign words skipped**: Should NOT happen with this method! Report if it does.
        - **Weird timing**: Very long texts cause drift - split into paragraphs
        - **Too many/few pauses**: Adjust pause level setting
        
        ### Best Practices:
        - âœ… Keep texts under 500 words for best timing accuracy
        - âœ… Use clear paragraph breaks (double newlines)
        - âœ… Test with different pause levels to find sweet spot
        - âœ… For very long texts, process in sections
        """)

    # Connect button to function
    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

# Launch with public link
demo.queue().launch(share=True)
