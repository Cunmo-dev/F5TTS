import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def post_process(text, silence_duration=0.3):
    """
    X·ª≠ l√Ω vƒÉn b·∫£n v·ªõi c√°c quy t·∫Øc th√¥ng minh:
    1. Ph√°t hi·ªán c√°c c√¢u h·ªôi tho·∫°i/c√¢u ƒë·ªôc l·∫≠p b·ªã gh√©p nh·∫ßm b·∫±ng d·∫•u ph·∫©y
    2. Gi·ªØ d·∫•u ph·∫©y cho c√°c c√¢u c√≥ ng·ªØ nghƒ©a li√™n k·∫øt
    3. Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    4. Th√™m kho·∫£ng l·∫∑ng gi·ªØa c√°c c√¢u
    """
    
    # Danh s√°ch c√°c t·ª´/c·ª•m t·ª´ th∆∞·ªùng l√† c√¢u ƒë·ªôc l·∫≠p (h·ªôi tho·∫°i, c·∫£m th√°n)
    independent_phrases = [
        # 1. Ti·∫øng c·∫£m th√°n / K√™u g·ªçi
        r'\b√†\b', r'\b·ªù\b', r'\b∆∞\b', r'\b·ª´\b', r'\ba\b',
        r'\bai\b', r'\b∆°i\b', r'\b·ª•i\b', r'\b√™\b',
        
        # 2. ƒê√°p l·ªùi l·ªãch s·ª±
        r'\bd·∫°\b', r'\bv√¢ng\b', r'\b·∫°\b', r'\b∆°\b',
        r'\bd·∫°\s+(c·∫≠u|anh|ch·ªã|m√°|ba|√¥ng|b√†)',
        
        # 3. C√¢u tr·∫£ l·ªùi ng·∫Øn ƒë∆°n ƒë·ªôc
        r'^\s*(kh√¥ng|c√≥|r·ªìi|ch∆∞a|ƒë∆∞·ª£c|·ª´|·ªù)\s*$',
        r'^\s*(ƒë√∫ng|sai|ph·∫£i|n√†o|th√¥i|ƒëi)\s*$',
        
        # 4. NgƒÉn c·∫£n / Y√™u c·∫ßu d·ª´ng l·∫°i
        r'\bkhoan\s+(ƒë√£|l·∫°i|n√†o)\b', r'\bƒë·ª£i\s+(ƒë√£|ch√∫t|t√≠|t√Ω)\b',
        r'\bƒë·ª´ng\b', r'\bch·∫≠m\s+l·∫°i\b', r'\bd·ª´ng\s+l·∫°i\b',
        
        # 5. Th√∫c gi·ª•c / Ra l·ªánh ng·∫Øn
        r'\bmau\b', r'\bnhanh\b', r'\bch·∫°y\b', r'\bƒëi\s+nhanh\b',
        r'\bmau\s+l√™n\b', r'\bnhanh\s+l√™n\b',
        
        # 6. H·ªèi ng·∫Øn (c√¢u h·ªèi tag)
        r'\bsao\b', r'\bv·∫≠y\s+sao\b', r'\bth·∫ø\s+n√†o\b',
        r'\bhay\s+sao\b', r'\bph·∫£i\s+(kh√¥ng|chƒÉng)\b',
        r'\bch·ª©\b', r'\bnh·ªâ\b', r'\bnh√©\b',
        
        # 7. X√°c nh·∫≠n / ƒê·ªìng √Ω
        r'^\s*ƒë∆∞·ª£c\s+(r·ªìi|l·∫Øm|th√¥i|ƒë√≥)\s*$',
        r'^\s*t·ªët\s+(r·ªìi|l·∫Øm|th√¥i)\s*$',
        r'^\s*(·ª´|·ªù|uhm|uh)\s+(nh·ªâ|nh√©|√†)?\s*$',
        
        # 8. L·ªùi ch√†o / T·ª´ bi·ªát
        r'\bxin\s+ch√†o\b', r'\bt·∫°m\s+bi·ªát\b', r'\bch√†o\b',
        r'\bh·∫πn\s+g·∫∑p\s+l·∫°i\b', r'\bch√∫c\s+ng·ªß\s+ngon\b',
        
        # 9. L·ªùi c·∫£m ∆°n / Xin l·ªói
        r'\bc·∫£m\s+∆°n\b', r'\bc√°m\s+∆°n\b', r'\bxin\s+l·ªói\b',
        r'\bl√†m\s+∆°n\b', r'\bxin\s+c·∫≠u\b',
        
        # 10. C√¢u h·ªèi WH- ng·∫Øn
        r'^\s*(ai|g√¨|ƒë√¢u|n√†o|sao|th·∫ø\s+n√†o|chi)\s*$',
        r'^\s*(c√°i\s+g√¨|l√†m\s+sao|th·∫ø\s+n√†o)\s*$',
        
        # 11. Ti·∫øng k√™u h√©t / S·ª£ h√£i
        r'^\s*(√°|a|∆°i|√∫i|tr·ªùi|ch·∫øt|m·∫π\s+∆°i)\s*$',
        
        # 12. C√¢u ng·∫Øn v·ªõi t·ª´ g·ªçi (vocative)
        r'\b(c·∫≠u|anh|ch·ªã|em|m√°|ba|√¥ng|b√†)\s+(∆°i|√†|·∫°|nh√©)\s*$',
        
        # 13. H·ªèi ng·∫Øn v·ªõi ƒë·ªông t·ª´
        r'^\s*(c√≥\s+ph·∫£i|c√≥\s+ƒë∆∞·ª£c|c√≥\s+th·ªÉ)\s+.{0,15}\s+(kh√¥ng|chƒÉng|hay\s+sao)\s*$',
    ]
    
    # ƒê√°nh d·∫•u c√°c ƒëo·∫°n text trong d·∫•u ngo·∫∑c k√©p
    quoted_sections = []
    placeholder_pattern = "<<<QUOTED_{}>>>"
    
    def save_quoted_text(match):
        index = len(quoted_sections)
        quoted_sections.append(match.group(0))
        return placeholder_pattern.format(index)
    
    text = re.sub(r'"[^"]*"', save_quoted_text, text)
    
    # ===== X·ª¨ L√ù TH√îNG MINH D·∫§U PH·∫®Y =====
    def smart_comma_split(sentence):
        """
        T√°ch d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m n·∫øu:
        - Sau d·∫•u ph·∫©y l√† c√¢u ƒë·ªôc l·∫≠p (h·ªôi tho·∫°i, c·∫£m th√°n)
        - Tr∆∞·ªõc ho·∫∑c sau d·∫•u ph·∫©y c√≥ placeholder (ngo·∫∑c k√©p)
        """
        parts = sentence.split(',')
        
        if len(parts) <= 1:
            return [sentence]
        
        result = []
        current = parts[0].strip()
        
        for i in range(1, len(parts)):
            next_part = parts[i].strip()
            is_independent = False
            
            # 1. Ki·ªÉm tra c√°c t·ª´/c·ª•m t·ª´ ƒë·ªôc l·∫≠p
            for pattern in independent_phrases:
                if re.search(pattern, next_part, re.IGNORECASE):
                    is_independent = True
                    break
            
            # 2. Ki·ªÉm tra n·∫øu c√≥ placeholder (ngo·∫∑c k√©p)
            if '<<<QUOTED_' in current or '<<<QUOTED_' in next_part:
                is_independent = True
            
            # 3. Ki·ªÉm tra n·∫øu ph·∫ßn ti·∫øp theo qu√° ng·∫Øn v√† kh√¥ng c√≥ t·ª´ li√™n k·∫øt
            linking_words = ['c·ªßa', 'v√†', 'v·ªõi', 'cho', 'b·ªüi', 'l√†', '·ªü', 't·∫°i', 'trong', 
                           'ngo√†i', 'tr√™n', 'd∆∞·ªõi', 'theo', 'nh∆∞ng', 'm√†', 'th√¨', 'n√™n']
            
            if len(next_part) < 20 and not any(word in next_part.lower() for word in linking_words):
                transition_verbs = ['n√≥i', 'h·ªèi', 'k√™u', 'g·ªçi', 'la', 'th√©t', 'r·∫±ng', 'l√†']
                if not any(current.strip().endswith(v) for v in transition_verbs):
                    is_independent = True
            
            # 4. Ki·ªÉm tra pattern ƒë·∫∑c bi·ªát
            if current.strip().endswith(':') or current.strip().endswith('"'):
                is_independent = True
            
            if is_independent:
                if current:
                    result.append(current)
                current = next_part
            else:
                current += ', ' + next_part
        
        if current:
            result.append(current)
        
        return result
    
    # T√°ch c√¢u theo d·∫•u ch·∫•m
    sentences_by_period = text.split('.')
    
    all_sentences = []
    for sent in sentences_by_period:
        sent = sent.strip()
        if not sent:
            continue
        
        sub_sentences = smart_comma_split(sent)
        all_sentences.extend(sub_sentences)
    
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    special_chars_pattern = r'[!@#$%^&*()_+=\[\]{};:\\|<>/?~`"\']'
    
    processed_sentences = []
    for sentence in all_sentences:
        if not sentence:
            continue
        
        if '<<<QUOTED_' not in sentence:
            sentence = re.sub(special_chars_pattern, '', sentence)
        
        sentence = sentence.strip()
        if sentence:
            processed_sentences.append(sentence)
    
    # X·ª≠ l√Ω c√°c ƒëo·∫°n text trong d·∫•u ngo·∫∑c k√©p
    def process_quoted_text(quoted_with_marks):
        quoted = quoted_with_marks.strip('"')
        special_chars_pattern_quote = r'[!@#$%^&*()_+=\[\]{};:\\|<>/?~`]'
        quoted = re.sub(special_chars_pattern_quote, '', quoted)
        quoted = " ".join(quoted.split())
        return '"' + quoted + '"'
    
    # Kh√¥i ph·ª•c v√† x·ª≠ l√Ω c√°c ƒëo·∫°n text trong ngo·∫∑c k√©p
    final_sentences = []
    for sentence in processed_sentences:
        for i, quoted_section in enumerate(quoted_sections):
            placeholder = placeholder_pattern.format(i)
            if placeholder in sentence:
                processed_quoted = process_quoted_text(quoted_section)
                sentence = sentence.replace(placeholder, processed_quoted)
        
        final_sentences.append(sentence)
    
    # N·ªëi c√°c c√¢u l·∫°i v·ªõi silence marker
    if silence_duration > 0:
        num_dots = int(silence_duration * 10)
        silence_marker = "." * num_dots
        text = silence_marker.join(final_sentences) + "."
    else:
        text = ". ".join(final_sentences) + "."
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = " ".join(text.split())
    
    return text

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, silence_duration: float = 0.3, request: gr.Request = None):
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        
        # X·ª≠ l√Ω text v·ªõi silence duration
        processed_text = post_process(TTSnorm(gen_text), silence_duration).lower()
        
        # Ch·∫°y inference
        final_wave, final_sample_rate, spectrogram = infer_process(
            ref_audio, ref_text.lower(), processed_text, model, vocoder, speed=speed
        )
        
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        return (final_sample_rate, final_wave), spectrogram_path
    except Exception as e:
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # üé§ F5-TTS: Vietnamese Text-to-Speech Synthesis
    # The model was trained with approximately 1000 hours of data on a RTX 3090 GPU
    Enter text and upload a sample voice to generate natural speech.
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="üîä Sample Voice", type="filepath")
        gen_text = gr.Textbox(label="üìù Text", placeholder="Enter the text to generate voice...", lines=3)
    
    with gr.Row():
        speed = gr.Slider(0.3, 2.0, value=1.0, step=0.1, label="‚ö° Speed")
        silence_duration = gr.Slider(0.0, 2.0, value=0.3, step=0.1, label="üîá Silence Between Sentences (seconds)")
    
    btn_synthesize = gr.Button("üî• Generate Voice")
    
    with gr.Row():
        output_audio = gr.Audio(label="üéß Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="üìä Spectrogram")
    
    model_limitations = gr.Textbox(
        value="""1. This model may not perform well with numerical characters, dates, special characters, etc. => A text normalization module is needed.
2. The rhythm of some generated audios may be inconsistent or choppy => It is recommended to select clearly pronounced sample audios with minimal pauses for better synthesis quality.
3. Default, reference audio text uses the pho-whisper-medium model, which may not always accurately recognize Vietnamese, resulting in poor voice synthesis quality.
4. Inference with overly long paragraphs may produce poor results.
5. Smart comma handling: splits independent phrases (interjections, short responses) while preserving commas in contextual sentences.""", 
        label="‚ùó Model Limitations",
        lines=5,
        interactive=False
    )

    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, silence_duration], 
        outputs=[output_audio, output_spectrogram]
    )

# Run Gradio with share=True to get a gradio.live link
demo.queue().launch(share=True)
