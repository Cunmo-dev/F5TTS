import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACAHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def convert_time_to_dots(pause_seconds, dots_per_second=10):
    """
    Chuyá»ƒn Ä‘á»•i thá»i gian pause (giÃ¢y) thÃ nh sá»‘ lÆ°á»£ng dots.
    
    Args:
        pause_seconds: Thá»i gian pause mong muá»‘n (giÃ¢y)
        dots_per_second: Há»‡ sá»‘ chuyá»ƒn Ä‘á»•i (máº·c Ä‘á»‹nh: 10 dots = 1 giÃ¢y)
    
    Returns:
        str: Chuá»—i dots tÆ°Æ¡ng á»©ng
    """
    num_dots = max(2, int(pause_seconds * dots_per_second))  # Tá»‘i thiá»ƒu 2 dots
    return "." * num_dots

def add_natural_pauses(text, pause_level="Medium"):
    """
    ThÃªm kÃ½ hiá»‡u Ä‘áº·c biá»‡t Ä‘á»ƒ táº¡o khoáº£ng dá»«ng tá»± nhiÃªn.
    Sá»­ dá»¥ng thá»i gian (giÃ¢y) Ä‘á»ƒ tÃ­nh sá»‘ dots tÆ°Æ¡ng á»©ng.
    """
    # Cáº¥u hÃ¬nh pause theo thá»i gian (giÃ¢y)
    pause_time_configs = {
        "Short": (0.4, 0.2),    # Paragraph: 0.4s, Dialogue: 0.2s
        "Medium": (0.8, 0.4),   # Paragraph: 0.8s, Dialogue: 0.4s
        "Long": (1.2, 0.6)      # Paragraph: 1.2s, Dialogue: 0.6s
    }
    
    pause_paragraph_time, pause_dialogue_time = pause_time_configs.get(
        pause_level, (0.8, 0.4)
    )
    
    # Chuyá»ƒn Ä‘á»•i thá»i gian thÃ nh dots
    # CÃ´ng thá»©c: 1 giÃ¢y â‰ˆ 5 dots (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
    dots_per_second = 5
    pause_paragraph = convert_time_to_dots(pause_paragraph_time, dots_per_second)
    pause_dialogue = convert_time_to_dots(pause_dialogue_time, dots_per_second)
    
    print(f"\nğŸ›ï¸ Pause configuration:")
    print(f"   Level: {pause_level}")
    print(f"   Paragraph: {pause_paragraph_time}s â†’ '{pause_paragraph}' ({len(pause_paragraph)} dots)")
    print(f"   Dialogue: {pause_dialogue_time}s â†’ '{pause_dialogue}' ({len(pause_dialogue)} dots)")
    
    # TÃ¡ch theo dÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n biá»‡t Ä‘oáº¡n vÄƒn
    paragraphs = text.split('\n\n')
    processed_paragraphs = []
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # Gá»™p cÃ¡c dÃ²ng trong cÃ¹ng Ä‘oáº¡n
        lines = para.split('\n')
        combined_text = ' '.join(line.strip() for line in lines if line.strip())
        
        # Kiá»ƒm tra há»™i thoáº¡i (cÃ³ dáº¥u ngoáº·c)
        has_quotes = '"' in combined_text or '"' in combined_text or '"' in combined_text
        is_dialogue = has_quotes
        
        pause_marker = pause_dialogue if is_dialogue else pause_paragraph
        
        # Thay tháº¿ dáº¥u cÃ¢u cuá»‘i báº±ng dáº¥u cÃ¢u + pause marker
        # VÃ­ dá»¥: "Xin chÃ o." -> "Xin chÃ o. ....."
        combined_text = re.sub(r'([.!?])(\s|$)', r'\1 ' + pause_marker + r'\2', combined_text)
        
        processed_paragraphs.append(combined_text)
    
    result = '\n\n'.join(processed_paragraphs)
    
    print(f"\nğŸ“ Processed text preview:")
    print(result[:300] + "..." if len(result) > 300 else result)
    
    return result

def post_process(text):
    """LÃ m sáº¡ch vÄƒn báº£n - GIá»® Láº I dáº¥u cháº¥m láº·p Ä‘á»ƒ táº¡o pause."""
    text = " " + text + " "
    # KHÃ”NG gá»™p dáº¥u cháº¥m láº·p - Ä‘á»ƒ model tá»± xá»­ lÃ½
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = text.replace('"', "")
    # Chá»‰ gá»™p dáº¥u pháº©y dÆ° thá»«a
    text = re.sub(r',+', ',', text)
    text = text.replace(" , ", " ")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    TTS inference - xá»­ lÃ½ toÃ n bá»™ vÄƒn báº£n má»™t láº§n vá»›i pause markers.
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ¤ Starting TTS generation")
        print(f"{'='*60}")
        
        # ThÃªm pause markers vÃ o vÄƒn báº£n
        processed_text = add_natural_pauses(gen_text, pause_level)
        
        print(f"\nğŸ“Š Stats:")
        print(f"   Original length: {len(gen_text)} chars")
        print(f"   Processed length: {len(processed_text)} chars")
        print(f"   Word count: {len(processed_text.split())} words")
        
        # Preprocess reference audio
        print(f"\nğŸ”„ Processing reference audio...")
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        print(f"   Reference text: {ref_text[:100]}...")
        
        # Chuáº©n hÃ³a vÄƒn báº£n (giá»¯ láº¡i dáº¥u cháº¥m láº·p)
        normalized_text = post_process(TTSnorm(processed_text)).lower()
        
        print(f"\nğŸ“ Normalized text preview:")
        print(f"   {normalized_text[:200]}...")
        
        # Táº¡o audio - Xá»¬ LÃ TOÃ€N Bá»˜ Má»˜T Láº¦N
        print(f"\nğŸµ Generating audio...")
        final_wave, final_sample_rate, spectrogram = infer_process(
            ref_audio, 
            ref_text.lower(), 
            normalized_text, 
            model, 
            vocoder, 
            speed=speed
        )
        
        duration = len(final_wave) / final_sample_rate
        print(f"\nâœ… Audio generated successfully!")
        print(f"   Duration: {duration:.2f}s")
        print(f"   Sample rate: {final_sample_rate}Hz")
        print(f"{'='*60}\n")
        
        # LÆ°u spectrogram
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        return (final_sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤ F5-TTS: Vietnamese Text-to-Speech Synthesis
    ### Model trained with ~1000 hours of data on RTX 3090 GPU
    
    Enter text and upload a sample voice to generate natural speech with **time-based intelligent pause control**.
    
    âœ¨ **Smart Pause Feature**: Converts pause time (seconds) to dot markers automatically!
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ğŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ğŸ“ Text to Generate", 
            placeholder="""Enter text with paragraphs separated by blank lines...

Example:
Háº¯n lÃºc nÃ y Ä‘ang ngá»“i trÃªn boong tÃ u. Máº¯t nhÃ¬n ra biá»ƒn xa.

"Toa láº§n nÃ y trá»Ÿ vá» nhÃ  chÆ¡i Ä‘Æ°á»£c bao lÃ¢u?"

NgÆ°á»i há»i lÃ  má»™t ngÆ°á»i báº¡n tÃ¬nh cá» gáº·p.

"Meci beaucoup!"
""", 
            lines=10
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="âš¡ Speed"
        )
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Controls natural pauses after sentences (time-based)"
        )
    
    btn_synthesize = gr.Button("ğŸ”¥ Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="ğŸ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ğŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ğŸ’¡ How Time-Based Pause Works:
    
    | Feature | Description |
    |---------|-------------|
    | **Time Configuration** | Set pause duration in seconds (e.g., 0.4s, 0.8s) |
    | **Auto Conversion** | Converts time to dots (1 second â‰ˆ 5 dots) |
    | **Paragraph vs Dialogue** | Different pause times for narrative and speech |
    | **Single-Pass Processing** | Entire text processed at once (no splitting!) |
    | **Consistent Logic** | Same dot-based approach, just smarter configuration |
    
    ### ğŸ“– Pause Levels (Time â†’ Dots):
    
    | Level | Paragraph | Dialogue | Use Case |
    |-------|-----------|----------|----------|
    | **Short** | 0.4s (2 dots) | 0.2s (1 dot) | News, fast reading |
    | **Medium** | 0.8s (4 dots) | 0.4s (2 dots) | Stories, audiobooks |
    | **Long** | 1.2s (6 dots) | 0.6s (3 dots) | Dramatic reading |
    
    ### ğŸ¯ Example Processing:
    
    **Input (with Medium level):**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. Máº¯t nhÃ¬n ra biá»ƒn.
    
    "Xin chÃ o!"
    ```
    
    **After Time-Based Conversion:**
    ```
    Paragraph (0.8s â†’ 4 dots):
    Háº¯n ngá»“i trÃªn tÃ u. .... Máº¯t nhÃ¬n ra biá»ƒn. ....
    
    Dialogue (0.4s â†’ 2 dots):
    "Xin chÃ o!" ..
    ```
    
    ### âœ… Advantages:
    - â±ï¸ **Intuitive Configuration** - think in seconds, not dots!
    - ğŸµ **Natural Rhythm** - automatic conversion ensures consistency
    - âš¡ **Fast Processing** - single pass through model
    - ğŸ”§ **Easy Adjustment** - change `dots_per_second` to fine-tune
    - ğŸ“Š **Predictable Results** - time-based settings are easier to understand
    
    ### ğŸ”§ Technical Details:
    - **Conversion Formula**: `num_dots = pause_seconds Ã— dots_per_second`
    - **Default Rate**: 5 dots/second (adjustable in code)
    - **Minimum**: Always at least 2 dots to ensure pause effect
    
    ### ğŸ“ Usage Tips:
    - Separate major sections with **double line breaks** (`\\n\\n`)
    - Quote dialogue: `"Hello," she said.`
    - Short sentences are automatically handled (no skipping!)
    - Experiment with pause levels to find what sounds best
    - If pauses too long/short, adjust `dots_per_second` in code
    """)
    
    with gr.Accordion("â— Model Limitations", open=False):
        gr.Markdown("""
        1. **Numbers & Special Characters**: May not handle dates, phone numbers perfectly
        2. **Audio Quality**: Use clear reference audio with minimal background noise
        3. **Reference Text**: Auto-transcribed using Whisper (may have errors)
        4. **Very Long Text**: Texts over 1000 words may produce inconsistent results
        5. **Foreign Words**: May not pronounce non-Vietnamese words correctly
        6. **Dot Calibration**: The 5 dots/second default may need adjustment based on model behavior
        
        ### ğŸ”§ Troubleshooting:
        - If pauses too long: decrease `dots_per_second` (try 3-4)
        - If pauses too short: increase `dots_per_second` (try 6-8)
        - If you hear weird sounds, use "Short" pause level
        - For very long texts, consider splitting into multiple generations
        """)

    # Connect button to function
    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

# Launch with public link
demo.queue().launch(share=True)
