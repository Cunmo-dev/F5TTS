import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def add_smart_pauses(text, pause_paragraph='...', pause_dialogue='..'):
    """
    ThÃªm kÃ½ tá»± Ä‘áº·c biá»‡t vÃ o vÄƒn báº£n Ä‘á»ƒ táº¡o khoáº£ng dá»«ng tá»± nhiÃªn.
    
    Args:
        pause_paragraph: kÃ½ tá»± cho khoáº£ng dá»«ng sau Ä‘oáº¡n vÄƒn táº£ (máº·c Ä‘á»‹nh: '...')
        pause_dialogue: kÃ½ tá»± cho khoáº£ng dá»«ng sau há»™i thoáº¡i (máº·c Ä‘á»‹nh: '..')
    """
    
    lines = text.split('\n')
    processed_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            processed_lines.append('')
            continue
        
        # Kiá»ƒm tra náº¿u lÃ  há»™i thoáº¡i (báº¯t Ä‘áº§u báº±ng dáº¥u ngoáº·c kÃ©p)
        is_dialogue_line = line.startswith('"') or line.startswith('"') or line.startswith('"')
        
        if is_dialogue_line:
            # Vá»›i há»™i thoáº¡i: thÃªm pause ngáº¯n sau má»—i cÃ¢u
            # TÃ¬m cÃ¡c dáº¥u káº¿t thÃºc cÃ¢u
            line = re.sub(r'([.!?])\s+', r'\1 ' + pause_dialogue + ' ', line)
            processed_lines.append(line)
        else:
            # Vá»›i Ä‘oáº¡n vÄƒn táº£: thÃªm pause dÃ i hÆ¡n
            line = re.sub(r'([.!?])\s+', r'\1 ' + pause_paragraph + ' ', line)
            processed_lines.append(line)
    
    # GhÃ©p láº¡i vÃ  lÃ m sáº¡ch
    result = '\n'.join(processed_lines)
    
    # Loáº¡i bá» pause thá»«a á»Ÿ cuá»‘i
    result = re.sub(r'(\.\.\.|\.\.)\s*$', '', result)
    
    return result

def post_process(text):
    text = " " + text + " "
    text = text.replace(" . . ", " . ")
    text = " " + text + " "
    text = text.replace(" .. ", " . ")
    text = " " + text + " "
    text = text.replace(" , , ", " , ")
    text = " " + text + " "
    text = text.replace(" ,, ", " , ")
    text = " " + text + " "
    text = text.replace('"', "")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    Args:
        pause_level: má»©c Ä‘á»™ khoáº£ng dá»«ng ("Short", "Medium", "Long")
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        # Chá»n kÃ½ tá»± pause dá»±a trÃªn level
        pause_configs = {
            "Short": (".", ""),           # Pause ngáº¯n: dáº¥u cháº¥m thÃ´ng thÆ°á»ng
            "Medium": ("..", "."),        # Pause vá»«a: thÃªm 1-2 dáº¥u cháº¥m
            "Long": ("...", "..")         # Pause dÃ i: thÃªm 2-3 dáº¥u cháº¥m
        }
        
        pause_paragraph, pause_dialogue = pause_configs.get(pause_level, ("..", "."))
        
        print(f"\nðŸŽ›ï¸ Pause config: Paragraph='{pause_paragraph}', Dialogue='{pause_dialogue}'")
        
        # Xá»­ lÃ½ vÄƒn báº£n vá»›i smart pauses
        processed_text = add_smart_pauses(gen_text, pause_paragraph, pause_dialogue)
        
        print(f"\nðŸ“ Original text length: {len(gen_text)} chars")
        print(f"ðŸ“ Processed text length: {len(processed_text)} chars")
        print(f"\n--- PROCESSED TEXT ---")
        print(processed_text[:500] + "..." if len(processed_text) > 500 else processed_text)
        print("----------------------\n")
        
        # Preprocess reference audio
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        
        # Chuáº©n hÃ³a vÄƒn báº£n
        normalized_text = post_process(TTSnorm(processed_text)).lower()
        
        print(f"ðŸ”„ Normalized text: {normalized_text[:200]}...")
        
        # Táº¡o audio (Xá»¬ LÃ TOÃ€N Bá»˜ Má»˜T Láº¦N - nhÆ° code cÅ©)
        final_wave, final_sample_rate, spectrogram = infer_process(
            ref_audio, 
            ref_text.lower(), 
            normalized_text, 
            model, 
            vocoder, 
            speed=speed
        )
        
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        print("âœ… Audio generated successfully!")
        return (final_sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ðŸŽ¤ F5-TTS: Vietnamese Text-to-Speech Synthesis
    # The model was trained with approximately 1000 hours of data on a RTX 3090 GPU
    Enter text and upload a sample voice to generate natural speech with intelligent pausing.
    
    âœ¨ **New Feature**: Smart pause injection - automatically adds natural pauses without splitting sentences!
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ðŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ðŸ“ Text", 
            placeholder="Enter the text to generate voice (supports paragraphs and dialogue)...", 
            lines=8
        )
    
    with gr.Row():
        speed = gr.Slider(0.3, 2.0, value=1.0, step=0.1, label="âš¡ Speed")
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Short: minimal pauses | Medium: natural pauses | Long: dramatic pauses"
        )
    
    btn_synthesize = gr.Button("ðŸ”¥ Generate Voice", variant="primary")
    
    with gr.Row():
        output_audio = gr.Audio(label="ðŸŽ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ðŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ðŸ’¡ How it works:
    - **Smart Pause Injection**: Automatically detects sentence endings and dialogue
    - **No sentence splitting**: Processes entire text at once (more stable)
    - **Dialogue detection**: Shorter pauses for conversation flow
    - **Paragraph detection**: Longer pauses for narrative text
    
    ### ðŸ“Š Pause Levels:
    - **Short**: Quick reading, minimal breaks
    - **Medium**: Natural conversation pace (recommended)
    - **Long**: Dramatic reading, audiobook style
    """)
    
    with gr.Accordion("â— Model Limitations", open=False):
        gr.Markdown("""
        1. This model may not perform well with numerical characters, dates, special characters, etc.
        2. The rhythm of some generated audios may be inconsistent or choppy => Select clearly pronounced sample audios
        3. Reference audio text uses pho-whisper-medium model which may not always accurately recognize Vietnamese
        4. Very long paragraphs (>1000 words) may produce poor results
        """)

    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

demo.queue().launch(share=True)
