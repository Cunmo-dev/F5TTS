import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re
import numpy as np

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def split_text_smart(text, pause_paragraph_duration=0.8, pause_dialogue_duration=0.4):
    """
    TÃ¡ch vÄƒn báº£n thÃ´ng minh: GIá»® Láº I cÃ¡c cÃ¢u ngáº¯n (nhÆ° "Meci beaucoup!") 
    thay vÃ¬ bá» qua hoáº·c gá»™p cÆ°á»¡ng bá»©c.
    
    Returns:
        list of tuples: [(sentence, pause_duration_in_seconds), ...]
    """
    chunks = []
    
    # TÃ¡ch theo dÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n biá»‡t Ä‘oáº¡n vÄƒn
    paragraphs = text.split('\n\n')
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # Gá»™p cÃ¡c dÃ²ng trong cÃ¹ng Ä‘oáº¡n
        lines = para.split('\n')
        combined_text = ' '.join(line.strip() for line in lines if line.strip())
        
        # Kiá»ƒm tra há»™i thoáº¡i (cÃ³ dáº¥u ngoáº·c)
        has_quotes = '"' in combined_text or '"' in combined_text or '"' in combined_text
        is_dialogue = has_quotes
        pause_duration = pause_dialogue_duration if is_dialogue else pause_paragraph_duration
        
        # Loáº¡i bá» dáº¥u ngoáº·c kÃ©p
        clean_text = combined_text.replace('"', '').replace('"', '').replace('"', '').strip()
        
        # TÃ¡ch thÃ nh cÃ¡c cÃ¢u dá»±a trÃªn dáº¥u cÃ¢u
        sentences = re.split(r'([.!?]+)', clean_text)
        
        current_sentence = ""
        for i, part in enumerate(sentences):
            if i % 2 == 0:  # Pháº§n vÄƒn báº£n
                current_sentence += part
            else:  # Dáº¥u cÃ¢u
                current_sentence += part
                sentence_text = current_sentence.strip()
                
                # THAY Äá»”I QUAN TRá»ŒNG: Cháº¥p nháº­n Táº¤T Cáº¢ cÃ¡c cÃ¢u cÃ³ Ã­t nháº¥t 1 tá»«
                if sentence_text and len(sentence_text.split()) >= 1:
                    chunks.append((sentence_text, pause_duration))
                    current_sentence = ""
        
        # ThÃªm pháº§n cÃ²n láº¡i náº¿u cÃ³
        if current_sentence.strip():
            chunks.append((current_sentence.strip(), pause_duration))
    
    # KHÃ”NG Gá»˜P cÃ¡c cÃ¢u ngáº¯n - Ä‘á»ƒ model xá»­ lÃ½ táº¥t cáº£
    return chunks

def create_silence(duration_seconds, sample_rate=24000):
    """Táº¡o Ä‘oáº¡n im láº·ng vá»›i thá»i gian xÃ¡c Ä‘á»‹nh."""
    num_samples = int(duration_seconds * sample_rate)
    return np.zeros(num_samples, dtype=np.float32)

def post_process(text):
    """LÃ m sáº¡ch vÄƒn báº£n - tá»‘i giáº£n Ä‘á»ƒ giá»¯ nguyÃªn tá»« ngoáº¡i ngá»¯."""
    text = " " + text + " "
    # Chá»‰ loáº¡i bá» dáº¥u ngoáº·c kÃ©p vÃ  khoáº£ng tráº¯ng dÆ° thá»«a
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = text.replace('"', "")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    TTS inference HYBRID: Äá»c Ä‘áº§y Ä‘á»§ + Pause tá»± nhiÃªn.
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        # Cáº¥u hÃ¬nh pause (giÃ¢y)
        pause_configs = {
            "Short": (0.3, 0.15),   # Paragraph: 0.3s, Dialogue: 0.15s
            "Medium": (0.5, 0.25),  # Paragraph: 0.5s, Dialogue: 0.25s
            "Long": (0.8, 0.4)      # Paragraph: 0.8s, Dialogue: 0.4s
        }
        
        pause_paragraph, pause_dialogue = pause_configs.get(pause_level, (0.5, 0.25))
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤ HYBRID TTS Generation")
        print(f"{'='*60}")
        print(f"ğŸ›ï¸ Pause config: Paragraph={pause_paragraph}s, Dialogue={pause_dialogue}s")
        
        # TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c cÃ¢u (GIá»® Láº I táº¥t cáº£ cÃ¢u)
        chunks = split_text_smart(gen_text, pause_paragraph, pause_dialogue)
        
        print(f"\nğŸ“ Total chunks: {len(chunks)}")
        for idx, (sent, pause) in enumerate(chunks[:5], 1):
            print(f"   {idx}. [{pause}s pause] {sent[:70]}...")
        
        if not chunks:
            raise gr.Error("No valid sentences found in text. Please check your input.")
        
        # Preprocess reference audio
        print(f"\nğŸ”„ Processing reference audio...")
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        print(f"   Reference text: {ref_text[:100]}...")
        
        # Táº¡o audio cho tá»«ng cÃ¢u vÃ  ghÃ©p láº¡i
        audio_segments = []
        sample_rate = 24000
        
        for i, (sentence, pause_duration) in enumerate(chunks):
            print(f"\nğŸ”„ [{i+1}/{len(chunks)}] Processing: {sentence}")
            
            # Chuáº©n hÃ³a vÄƒn báº£n (chá»‰ lowercase vÃ  trim)
            try:
                normalized_text = post_process(TTSnorm(sentence)).lower()
            except:
                # Náº¿u TTSnorm lá»—i vá»›i tá»« ngoáº¡i ngá»¯, dÃ¹ng vÄƒn báº£n gá»‘c
                normalized_text = post_process(sentence).lower()
            
            # QUAN TRá»ŒNG: Cháº¥p nháº­n Táº¤T Cáº¢ vÄƒn báº£n, ká»ƒ cáº£ ráº¥t ngáº¯n
            if len(normalized_text.strip()) < 2:
                print(f"   â­ï¸ Skipped (too short): '{normalized_text}'")
                continue
            
            print(f"   ğŸ“ Normalized: {normalized_text}")
            
            try:
                # Táº¡o audio cho cÃ¢u nÃ y
                wave, sr, _ = infer_process(
                    ref_audio, 
                    ref_text.lower(), 
                    normalized_text, 
                    model, 
                    vocoder, 
                    speed=speed
                )
                
                sample_rate = sr
                audio_segments.append(wave)
                duration = len(wave) / sr
                print(f"   âœ… Generated {duration:.2f}s audio")
                
                # ThÃªm khoáº£ng im láº·ng (trá»« cÃ¢u cuá»‘i)
                if i < len(chunks) - 1:
                    silence = create_silence(pause_duration, sample_rate)
                    audio_segments.append(silence)
                    print(f"   â¸ï¸  Added {pause_duration}s silence")
                    
            except Exception as e:
                print(f"   âŒ Error processing chunk: {e}")
                # KhÃ´ng bá» qua hoÃ n toÃ n, thá»­ vá»›i vÄƒn báº£n gá»‘c
                try:
                    print(f"   ğŸ”„ Retry with original text...")
                    wave, sr, _ = infer_process(
                        ref_audio, 
                        ref_text.lower(), 
                        sentence.lower(), 
                        model, 
                        vocoder, 
                        speed=speed
                    )
                    sample_rate = sr
                    audio_segments.append(wave)
                    print(f"   âœ… Success on retry!")
                    
                    if i < len(chunks) - 1:
                        silence = create_silence(pause_duration, sample_rate)
                        audio_segments.append(silence)
                except:
                    print(f"   âŒ Final skip")
                    continue
        
        # GhÃ©p táº¥t cáº£ audio láº¡i
        if not audio_segments:
            raise gr.Error("No valid audio segments generated. Please check your text.")
            
        final_wave = np.concatenate(audio_segments)
        
        total_duration = len(final_wave) / sample_rate
        num_sentences = (len(audio_segments) + 1) // 2
        
        print(f"\nâœ… FINAL RESULT:")
        print(f"   Duration: {total_duration:.2f}s")
        print(f"   Sentences: {num_sentences}")
        print(f"   Sample rate: {sample_rate}Hz")
        print(f"{'='*60}\n")
        
        # Táº¡o spectrogram
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            plt.figure(figsize=(14, 5))
            plt.specgram(final_wave, Fs=sample_rate, cmap='viridis')
            plt.xlabel('Time (s)')
            plt.ylabel('Frequency (Hz)')
            plt.title(f'Audio Spectrogram ({num_sentences} sentences, {total_duration:.1f}s)')
            plt.colorbar(format='%+2.0f dB')
            plt.tight_layout()
            plt.savefig(spectrogram_path, dpi=100)
            plt.close()

        return (sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤ F5-TTS Hybrid: Best of Both Worlds
    ### Model trained with ~1000 hours of data on RTX 3090 GPU
    
    **NEW APPROACH**: Combines complete text reading + natural silence pauses!
    
    âœ… **Reads ALL sentences** (even short ones like "Meci beaucoup!")  
    âœ… **Natural pauses** with real silence between sentences  
    âœ… **Foreign words preserved** (French, English, etc.)
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ğŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ğŸ“ Text to Generate", 
            placeholder="""Enter text with paragraphs separated by blank lines...

Example:
Háº¯n lÃºc nÃ y Ä‘ang ngá»“i trÃªn boong tÃ u. Máº¯t nhÃ¬n ra biá»ƒn xa.

"Toa láº§n nÃ y trá»Ÿ vá» nhÃ  chÆ¡i Ä‘Æ°á»£c bao lÃ¢u?"

NgÆ°á»i há»i lÃ  má»™t ngÆ°á»i báº¡n tÃ¬nh cá» gáº·p.

"Meci beaucoup!"

Há» cÃ¹ng cÆ°á»i vÃ  tiáº¿p tá»¥c hÃ nh trÃ¬nh.""", 
            lines=12
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="âš¡ Speed"
        )
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Real silence between sentences"
        )
    
    btn_synthesize = gr.Button("ğŸ”¥ Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="ğŸ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ğŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ğŸ’¡ How HYBRID Approach Works:
    
    | Feature | Description |
    |---------|-------------|
    | **Complete Reading** | ALL sentences are processed (no skipping!) |
    | **Smart Splitting** | Sentences split by punctuation (`.!?`) |
    | **Real Silence** | Actual silent gaps inserted between audio |
    | **Foreign Word Safe** | Preserves non-Vietnamese text |
    | **Auto Recovery** | Retries with original text if normalization fails |
    
    ### ğŸ“– Pause Levels:
    - **Short** (0.3s/0.15s): Quick reading - news, announcements
    - **Medium** (0.5s/0.25s): Natural storytelling - **recommended**
    - **Long** (0.8s/0.4s): Dramatic pauses - audiobooks, poetry
    
    *(First number = paragraph pause, Second = dialogue pause)*
    
    ### ğŸ¯ Example Processing:
    
    **Input:**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. Máº¯t nhÃ¬n ra biá»ƒn.
    
    "Toa vá» nhÃ  chÆ¡i bao lÃ¢u?"
    
    NgÆ°á»i há»i lÃ  báº¡n cÅ©.
    
    "Meci beaucoup!"
    ```
    
    **Output:** 
    ```
    [Audio: "Háº¯n ngá»“i trÃªn tÃ u"]
    [Silence: 0.5s]
    [Audio: "Máº¯t nhÃ¬n ra biá»ƒn"]
    [Silence: 0.5s]
    [Audio: "Toa vá» nhÃ  chÆ¡i bao lÃ¢u"]
    [Silence: 0.25s]
    [Audio: "NgÆ°á»i há»i lÃ  báº¡n cÅ©"]
    [Silence: 0.5s]
    [Audio: "Meci beaucoup"]  â† âœ… Not skipped!
    ```
    
    ### âœ¨ Key Improvements:
    
    1. **No Sentence Skipping**: 
       - Old: "Meci beaucoup!" â†’ âŒ Skipped (too short)
       - New: "Meci beaucoup!" â†’ âœ… **Processed!**
    
    2. **Better Pause Quality**:
       - Old: Fake pauses with `...` dots
       - New: **Real silence** (0.3-0.8 seconds)
    
    3. **Fallback Protection**:
       - If TTSnorm fails â†’ automatically retries with original text
       - Foreign words won't break the process
    
    ### ğŸ“ Usage Tips:
    - Use **double line breaks** (`\\n\\n`) to separate major sections
    - Quote dialogue: `"Hello," she said.`
    - Short sentences (1-2 words) are now **fully supported**
    - Mix Vietnamese and foreign words freely
    - Adjust pause level to match your content style
    
    ### âš™ï¸ Technical Details:
    - Each sentence â†’ separate audio generation â†’ combined with silence
    - No text truncation or forced merging
    - Original text preserved when normalization fails
    - Sample rate: 24,000 Hz
    """)
    
    with gr.Accordion("â— Model Limitations & Tips", open=False):
        gr.Markdown("""
        ### Limitations:
        1. **Numbers**: Dates/phone numbers may not sound natural
        2. **Processing Time**: Longer than single-pass (but better quality!)
        3. **Reference Audio**: Needs clear audio without background noise
        4. **Very Long Texts**: Consider splitting into sections (>1000 words)
        
        ### Troubleshooting:
        - **Weird pronunciation?** â†’ Try different reference audio
        - **Pauses too long/short?** â†’ Adjust pause level
        - **Missing words?** â†’ Check console logs for errors
        - **Foreign words sound wrong?** â†’ This is expected; model trained on Vietnamese
        
        ### Best Practices:
        âœ… Use clear paragraph breaks  
        âœ… Keep sentences under 40 words  
        âœ… Use high-quality reference audio (3-10 seconds)  
        âœ… Test different pause levels for your content type  
        """)

    # Connect button to function
    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

# Launch with public link
demo.queue().launch(share=True)
