import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re
import numpy as np

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def is_repetitive_text(text):
    """
    Ki·ªÉm tra xem c√¢u c√≥ ph·∫£i l√† vƒÉn b·∫£n l·∫∑p l·∫°i kh√¥ng.
    V√≠ d·ª•: "H√° h√° h√°", "hu hu hu", "ha ha ha..."
    
    Returns:
        bool: True n·∫øu l√† vƒÉn b·∫£n l·∫∑p l·∫°i
    """
    # Lo·∫°i b·ªè d·∫•u c√¢u v√† chuy·ªÉn v·ªÅ lowercase
    clean_text = re.sub(r'[.!?,;:]', '', text).lower().strip()
    
    # T√°ch th√†nh c√°c t·ª´
    words = clean_text.split()
    
    # N·∫øu √≠t h∆°n 2 t·ª´, kh√¥ng coi l√† l·∫∑p
    if len(words) < 2:
        return False
    
    # Ki·ªÉm tra xem t·∫•t c·∫£ c√°c t·ª´ c√≥ gi·ªëng nhau kh√¥ng
    unique_words = set(words)
    
    # N·∫øu ch·ªâ c√≥ 1 t·ª´ duy nh·∫•t ƒë∆∞·ª£c l·∫∑p l·∫°i
    if len(unique_words) == 1:
        return True
    
    # Ki·ªÉm tra pattern l·∫∑p v·ªõi variation nh·ªè (v√≠ d·ª•: "h√† h√†", "h√° h√°")
    # Lo·∫°i b·ªè d·∫•u thanh ƒë·ªÉ so s√°nh
    normalized_words = []
    for word in words:
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát v√† d·∫•u thanh (gi·ªØ l·∫°i ch·ªØ c√°i c∆° b·∫£n)
        base_word = ''.join(c for c in word if c.isalpha())
        normalized_words.append(base_word)
    
    unique_normalized = set(normalized_words)
    
    # N·∫øu sau khi normalize ch·ªâ c√≤n 1 t·ª´ -> l√† l·∫∑p
    if len(unique_normalized) == 1 and len(normalized_words) >= 2:
        return True
    
    # Ki·ªÉm tra pattern l·∫∑p (v√≠ d·ª•: "ha ha", "he he")
    # N·∫øu 80% t·ª´ gi·ªëng nhau (cho ph√©p m·ªôt v√†i variation)
    if len(unique_normalized) <= max(2, len(words) * 0.3):
        return True
    
    return False

def clean_text_before_processing(text):
    """
    L√†m s·∫°ch text tr∆∞·ªõc khi x·ª≠ l√Ω: lo·∫°i b·ªè emoji v√† k√Ω t·ª± ƒë·∫∑c bi·ªát.
    """
    # Lo·∫°i b·ªè emoji (Unicode ranges)
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "\U0001F900-\U0001F9FF"  # supplemental symbols
        "\U0001FA00-\U0001FA6F"
        "]+", 
        flags=re.UNICODE
    )
    text = emoji_pattern.sub('', text)
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = ' '.join(text.split())
    
    return text.strip()

def extract_quoted_segments(text):
    """
    Tr√≠ch xu·∫•t c√°c ƒëo·∫°n trong ngo·∫∑c k√©p v√† text b√™n ngo√†i.
    
    Returns:
        list of tuples: [(text, is_quoted), ...]
    """
    # L√†m s·∫°ch text tr∆∞·ªõc
    text = clean_text_before_processing(text)
    
    segments = []
    # Pattern ƒë·ªÉ t√¨m text trong ngo·∫∑c k√©p (h·ªó tr·ª£ c·∫£ ", ", ")
    pattern = r'(["""])([^"""]+)(["""])'
    
    last_end = 0
    for match in re.finditer(pattern, text):
        # Text tr∆∞·ªõc ngo·∫∑c k√©p
        before_text = text[last_end:match.start()].strip()
        if before_text:
            segments.append((before_text, False))
        
        # Text trong ngo·∫∑c k√©p (kh√¥ng bao g·ªìm d·∫•u ngo·∫∑c)
        quoted_text = match.group(2).strip()
        if quoted_text:
            segments.append((quoted_text, True))
        
        last_end = match.end()
    
    # Text sau ngo·∫∑c k√©p cu·ªëi c√πng
    after_text = text[last_end:].strip()
    if after_text:
        segments.append((after_text, False))
    
    return segments

def split_text_into_sentences(text, pause_paragraph_duration=0.8, pause_dialogue_duration=0.4):
    """
    T√°ch vƒÉn b·∫£n th√†nh c√°c c√¢u, gi·ªØ nguy√™n c√¢u trong ngo·∫∑c k√©p.
    
    Returns:
        list of tuples: [(sentence, pause_duration_in_seconds, is_merged), ...]
    """
    chunks = []
    
    # T√°ch theo d√≤ng tr·ªëng ƒë·ªÉ ph√¢n bi·ªát ƒëo·∫°n vƒÉn
    paragraphs = text.split('\n\n')
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # T√°ch c√°c d√≤ng trong ƒëo·∫°n
        lines = para.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Tr√≠ch xu·∫•t c√°c segment (quoted v√† non-quoted)
            segments = extract_quoted_segments(line)
            
            if not segments:
                continue
            
            for segment_text, is_quoted in segments:
                if not segment_text.strip():
                    continue
                
                if is_quoted:
                    # C√¢u trong ngo·∫∑c k√©p -> gi·ªØ nguy√™n, d√πng pause dialogue
                    chunks.append((segment_text, pause_dialogue_duration, False))
                    print(f"   üí¨ Quoted dialogue: '{segment_text[:60]}...'")
                else:
                    # Text b√™n ngo√†i ngo·∫∑c k√©p -> t√°ch nh∆∞ b√¨nh th∆∞·ªùng
                    sentences = re.split(r'([.!?]+)', segment_text)
                    
                    current_sentence = ""
                    for i, part in enumerate(sentences):
                        if i % 2 == 0:  # Ph·∫ßn vƒÉn b·∫£n
                            current_sentence += part
                        else:  # D·∫•u c√¢u
                            current_sentence += part
                            sentence_text = current_sentence.strip()
                            
                            if sentence_text:
                                chunks.append((sentence_text, pause_paragraph_duration, False))
                                current_sentence = ""
                    
                    # Th√™m ph·∫ßn c√≤n l·∫°i n·∫øu c√≥
                    if current_sentence.strip():
                        chunks.append((current_sentence.strip(), pause_paragraph_duration, False))
    
    # G·ªôp c√°c c√¢u < 3 t·ª´ ho·∫∑c c√¢u l·∫∑p l·∫°i b·∫±ng d·∫•u ch·∫•m
    merged_chunks = []
    temp_sentences = []
    temp_pause = pause_paragraph_duration
    
    for i, (sentence, pause, _) in enumerate(chunks):
        word_count = len(sentence.split())
        is_last = (i == len(chunks) - 1)
        is_repetitive = is_repetitive_text(sentence)
        
        # Ki·ªÉm tra xem c√¢u c√≥ c·∫ßn g·ªôp kh√¥ng
        should_merge = (word_count < 3) or is_repetitive
        
        if not should_merge:
            # C√¢u ƒë·ªß d√†i v√† kh√¥ng l·∫∑p
            if temp_sentences:
                # G·ªôp c√°c c√¢u t√≠ch l≈©y + c√¢u hi·ªán t·∫°i b·∫±ng d·∫•u ch·∫•m
                all_sentences = temp_sentences + [sentence]
                merged_text = ". ".join(all_sentences)
                merged_chunks.append((merged_text, pause, True))
                print(f"   üîó Merged sentences: '{merged_text[:80]}...'")
                temp_sentences = []
            else:
                # C√¢u ƒë·ªôc l·∫≠p
                merged_chunks.append((sentence, pause, False))
        else:
            # C√¢u ng·∫Øn ho·∫∑c l·∫∑p, t√≠ch l≈©y
            if is_repetitive:
                print(f"   üîÅ Detected repetitive text: '{sentence}' - will merge")
            temp_sentences.append(sentence)
            temp_pause = pause
            
            # N·∫øu l√† c√¢u cu·ªëi -> g·ªôp v·ªõi c√¢u tr∆∞·ªõc
            if is_last:
                if merged_chunks:
                    last_sentence, last_pause, last_merged = merged_chunks[-1]
                    combined_text = last_sentence + ". " + ". ".join(temp_sentences)
                    merged_chunks[-1] = (combined_text, last_pause, True)
                    print(f"   üîó Merged last short/repetitive chunk(s)")
                    temp_sentences = []
                else:
                    merged_text = ". ".join(temp_sentences)
                    while len(merged_text.split()) < 3:
                        merged_text += " n√†y"
                    print(f"   ‚ö†Ô∏è Last chunk too short, padded: '{merged_text}'")
                    merged_chunks.append((merged_text, temp_pause, False))
                    temp_sentences = []
    
    # X·ª≠ l√Ω c√¢u c√≤n s√≥t
    if temp_sentences:
        if merged_chunks:
            last_sentence, last_pause, last_merged = merged_chunks[-1]
            combined_text = last_sentence + ". " + ". ".join(temp_sentences)
            merged_chunks[-1] = (combined_text, last_pause, True)
            print(f"   üîó Merged remaining short/repetitive chunks")
        else:
            merged_text = ". ".join(temp_sentences)
            while len(merged_text.split()) < 3:
                merged_text += " n√†y"
            print(f"   ‚ö†Ô∏è Only short sentence(s) found, padded: '{merged_text}'")
            merged_chunks.append((merged_text, temp_pause, False))
    
    return merged_chunks

def create_silence(duration_seconds, sample_rate=24000):
    """T·∫°o ƒëo·∫°n im l·∫∑ng v·ªõi th·ªùi gian x√°c ƒë·ªãnh."""
    num_samples = int(duration_seconds * sample_rate)
    return np.zeros(num_samples, dtype=np.float32)

def post_process(text):
    """L√†m s·∫°ch vƒÉn b·∫£n - lo·∫°i b·ªè t·∫•t c·∫£ k√Ω t·ª± ƒë·∫∑c bi·ªát."""
    # Lo·∫°i b·ªè t·∫•t c·∫£ d·∫•u c√¢u v√† k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ ch·ªØ c√°i, s·ªë v√† kho·∫£ng tr·∫Øng
    # Gi·ªØ l·∫°i c√°c k√Ω t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = " ".join(text.split()).strip()
    
    return text

def safe_normalize(text):
    """Normalize vƒÉn b·∫£n an to√†n, x·ª≠ l√Ω l·ªói v·ªõi t·ª´ ngo·∫°i ng·ªØ."""
    try:
        normalized = TTSnorm(text)
        if len(normalized.strip()) < 2:
            return text.lower()
        return normalized.lower()
    except Exception as e:
        print(f"   ‚ö†Ô∏è TTSnorm error: {e}, using original text")
        return text.lower()

def validate_text_for_tts(text):
    """Ki·ªÉm tra vƒÉn b·∫£n tr∆∞·ªõc khi ƒë∆∞a v√†o TTS."""
    text = ' '.join(text.split())
    
    words = text.split()
    if len(words) < 3:
        print(f"   ‚ö†Ô∏è Warning: Very short text ({len(words)} words)")
    
    return text

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_paragraph: float = 0.4, pause_dialogue: float = 0.2, request: gr.Request = None):
    """
    TTS inference v·ªõi pause th·ª±c s·ª± b·∫±ng c√°ch gh√©p audio.
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        print(f"\nüéõÔ∏è Pause config: Paragraph={pause_paragraph}s, Dialogue={pause_dialogue}s")
        
        # T√°ch vƒÉn b·∫£n th√†nh c√°c c√¢u v·ªõi th·ªùi gian d·ª´ng
        chunks = split_text_into_sentences(gen_text, pause_paragraph, pause_dialogue)
        
        print(f"\nüìù Total chunks: {len(chunks)}")
        for idx, (sent, pause, is_merged) in enumerate(chunks[:5], 1):
            marker = "üîó MERGED" if is_merged else "üìÑ SINGLE"
            print(f"   {idx}. [{marker}, {pause}s] {sent[:80]}...")
        
        if not chunks:
            raise gr.Error("No valid sentences found in text.")
        
        # Preprocess reference audio
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        
        # T·∫°o audio cho t·ª´ng c√¢u v√† gh√©p l·∫°i
        audio_segments = []
        sample_rate = 24000
        
        for i, (sentence, pause_duration, is_merged) in enumerate(chunks):
            print(f"\nüîÑ [{i+1}/{len(chunks)}] Processing: {sentence[:80]}...")
            
            # Chu·∫©n h√≥a vƒÉn b·∫£n
            normalized_text = safe_normalize(sentence)
            normalized_text = post_process(normalized_text)
            normalized_text = validate_text_for_tts(normalized_text)
            normalized_text = normalized_text.rstrip('.')
            
            word_count = len(normalized_text.strip().split())
            if word_count < 1:
                print(f"   ‚è≠Ô∏è Skipped (empty)")
                continue
            
            if word_count < 3:
                original_text = normalized_text
                normalized_text = normalized_text + " n√†y"
                print(f"   ‚ö†Ô∏è Short sentence padded: '{original_text}' -> '{normalized_text}'")
            
            print(f"   üìù Normalized ({len(normalized_text.split())} words): {normalized_text[:80]}...")
            
            # Retry logic
            max_retries = 2
            retry_count = 0
            success = False
            
            while retry_count <= max_retries and not success:
                try:
                    if retry_count > 0:
                        print(f"   üîÅ Retry {retry_count}/{max_retries}...")
                    
                    wave, sr, _ = infer_process(
                        ref_audio, 
                        ref_text.lower(), 
                        normalized_text, 
                        model, 
                        vocoder, 
                        speed=speed
                    )
                    
                    sample_rate = sr
                    audio_segments.append(wave)
                    print(f"   ‚úÖ Generated {len(wave)/sr:.2f}s audio")
                    success = True
                    
                    # Th√™m im l·∫∑ng gi·ªØa c√°c chunk
                    if i < len(chunks) - 1 and not is_merged:
                        silence = create_silence(pause_duration, sample_rate)
                        audio_segments.append(silence)
                        print(f"   ‚è∏Ô∏è  Added {pause_duration}s silence")
                    elif i < len(chunks) - 1 and is_merged:
                        print(f"   üîá No manual silence (merged sentence)")
                        
                except Exception as e:
                    retry_count += 1
                    print(f"   ‚ö†Ô∏è Attempt {retry_count} failed: {str(e)[:100]}")
                    
                    if retry_count > max_retries:
                        print(f"   ‚ùå Max retries reached, skipping")
                        if len(normalized_text.split()) > 3:
                            print(f"   üîß Trying with first 3 words...")
                            simplified_text = ' '.join(normalized_text.split()[:3])
                            try:
                                wave, sr, _ = infer_process(
                                    ref_audio, 
                                    ref_text.lower(), 
                                    simplified_text, 
                                    model, 
                                    vocoder, 
                                    speed=speed
                                )
                                sample_rate = sr
                                audio_segments.append(wave)
                                print(f"   ‚úÖ Generated with simplified text")
                                success = True
                            except:
                                print(f"   ‚ùå Simplified attempt failed")
                        break
                    
                    import time
                    time.sleep(0.5)
        
        # Gh√©p t·∫•t c·∫£ audio
        if not audio_segments:
            raise gr.Error("No valid audio segments generated.")
            
        final_wave = np.concatenate(audio_segments)
        
        print(f"\n‚úÖ Final audio: {len(final_wave)/sample_rate:.2f}s (from {len(chunks)} chunks)")
        
        # T·∫°o spectrogram
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            plt.figure(figsize=(12, 4))
            plt.specgram(final_wave, Fs=sample_rate, cmap='viridis')
            plt.xlabel('Time (s)')
            plt.ylabel('Frequency (Hz)')
            plt.title('Audio Spectrogram')
            plt.colorbar(format='%+2.0f dB')
            plt.tight_layout()
            plt.savefig(spectrogram_path)
            plt.close()

        return (sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {str(e)}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üé§ F5-TTS: Vietnamese Text-to-Speech Synthesis")
    
    with gr.Row():
        ref_audio = gr.Audio(label="üîä Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="üìù Text to Generate", 
            placeholder="Enter Vietnamese text here...", 
            lines=10
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="‚ö° Speed"
        )
        pause_paragraph = gr.Slider(
            minimum=0.0,
            maximum=1.0,
            value=0.4,
            step=0.05,
            label="‚è∏Ô∏è Pause (Paragraph)"
        )
        pause_dialogue = gr.Slider(
            minimum=0.0,
            maximum=1.0,
            value=0.2,
            step=0.05,
            label="‚è∏Ô∏è Pause (Dialogue)"
        )
    
    btn_synthesize = gr.Button("üî• Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="üéß Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="üìä Spectrogram")

    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_paragraph, pause_dialogue], 
        outputs=[output_audio, output_spectrogram]
    )

demo.queue().launch(share=True)
