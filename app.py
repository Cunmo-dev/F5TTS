import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re
import numpy as np

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def split_text_with_pause_markers(text, pause_level="Medium"):
    """
    TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n lá»›n (theo paragraph) vÃ  thÃªm pause markers.
    Má»—i Ä‘oáº¡n sáº½ Ä‘Æ°á»£c xá»­ lÃ½ riÃªng rá»“i ghÃ©p láº¡i vá»›i silence tháº­t.
    
    Returns:
        list of tuples: [(text_chunk, pause_duration_in_seconds), ...]
    """
    # Cáº¥u hÃ¬nh pause markers vÃ  thá»i gian silence
    pause_configs = {
        "Short": ("...", 0.3),      # 3 dots, 0.3s silence
        "Medium": (".....", 0.6),   # 5 dots, 0.6s silence  
        "Long": (".......", 1.0),   # 7 dots, 1.0s silence
    }
    
    pause_marker, silence_duration = pause_configs.get(pause_level, (".....", 0.6))
    
    print(f"\nğŸ›ï¸ Using pause marker: '{pause_marker}' + {silence_duration}s silence")
    
    # TÃ¡ch theo dÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n biá»‡t Ä‘oáº¡n vÄƒn
    paragraphs = text.split('\n\n')
    chunks = []
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # Gá»™p cÃ¡c dÃ²ng trong cÃ¹ng Ä‘oáº¡n
        lines = para.split('\n')
        combined_text = ' '.join(line.strip() for line in lines if line.strip())
        
        # Kiá»ƒm tra há»™i thoáº¡i
        has_quotes = '"' in combined_text or '"' in combined_text or '"' in combined_text
        is_dialogue = has_quotes
        
        # ThÃªm pause marker vÃ o cuá»‘i cÃ¢u (giá»¯ nguyÃªn logic Code 1)
        processed_text = re.sub(r'([.!?])(\s|$)', r'\1 ' + pause_marker + r'\2', combined_text)
        
        # ThÃªm vÃ o danh sÃ¡ch vá»›i thá»i gian silence
        # Dialogue cÃ³ silence ngáº¯n hÆ¡n (má»™t ná»­a)
        actual_silence = silence_duration / 2 if is_dialogue else silence_duration
        chunks.append((processed_text, actual_silence))
        
        print(f"\nğŸ“ Chunk {len(chunks)} ({'dialogue' if is_dialogue else 'narrative'}):")
        print(f"   Text: {processed_text[:100]}...")
        print(f"   Silence: {actual_silence}s")
    
    return chunks

def create_silence(duration_seconds, sample_rate=24000):
    """Táº¡o Ä‘oáº¡n im láº·ng vá»›i thá»i gian xÃ¡c Ä‘á»‹nh."""
    num_samples = int(duration_seconds * sample_rate)
    return np.zeros(num_samples, dtype=np.float32)

def post_process(text):
    """LÃ m sáº¡ch vÄƒn báº£n - GIá»® Láº I dáº¥u cháº¥m láº·p."""
    text = " " + text + " "
    # KHÃ”NG gá»™p dáº¥u cháº¥m láº·p - Ä‘á»ƒ model tá»± xá»­ lÃ½
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = text.replace('"', "")
    # Chá»‰ gá»™p dáº¥u pháº©y dÆ° thá»«a
    text = re.sub(r',+', ',', text)
    text = text.replace(" , ", " ")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    HYBRID TTS: Xá»­ lÃ½ tá»«ng Ä‘oáº¡n lá»›n (nhÆ° Code 1) + thÃªm silence tháº­t (nhÆ° Code 2).
    
    Æ¯u Ä‘iá»ƒm:
    - KhÃ´ng bá» sÃ³t tá»« (xá»­ lÃ½ Ä‘oáº¡n lá»›n, khÃ´ng tÃ¡ch cÃ¢u nhá»)
    - Pause tá»± nhiÃªn (káº¿t há»£p pause marker + silence tháº­t)
    - Äá»c Ä‘Æ°á»£c tá»« nÆ°á»›c ngoÃ i (khÃ´ng normalize quÃ¡ má»©c)
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ¤ Starting HYBRID TTS generation")
        print(f"{'='*60}")
        
        # TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n vá»›i pause markers
        chunks = split_text_with_pause_markers(gen_text, pause_level)
        
        if not chunks:
            raise gr.Error("No valid paragraphs found. Please check your input.")
        
        print(f"\nğŸ“Š Total paragraphs to process: {len(chunks)}")
        
        # Preprocess reference audio
        print(f"\nğŸ”„ Processing reference audio...")
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        print(f"   Reference text: {ref_text[:100]}...")
        
        # Táº¡o audio cho tá»«ng Ä‘oáº¡n vÃ  ghÃ©p láº¡i
        audio_segments = []
        sample_rate = 24000
        
        for i, (chunk_text, silence_duration) in enumerate(chunks):
            print(f"\nğŸµ [{i+1}/{len(chunks)}] Generating audio for paragraph...")
            print(f"   Length: {len(chunk_text)} chars, {len(chunk_text.split())} words")
            
            # Chuáº©n hÃ³a vÄƒn báº£n (giá»¯ láº¡i dáº¥u cháº¥m láº·p)
            normalized_text = post_process(TTSnorm(chunk_text)).lower()
            print(f"   Normalized: {normalized_text[:150]}...")
            
            try:
                # Táº¡o audio cho Ä‘oáº¡n nÃ y (TOÃ€N Bá»˜ ÄOáº N Má»˜T Láº¦N)
                wave, sr, _ = infer_process(
                    ref_audio, 
                    ref_text.lower(), 
                    normalized_text, 
                    model, 
                    vocoder, 
                    speed=speed
                )
                
                sample_rate = sr
                audio_segments.append(wave)
                
                duration = len(wave) / sr
                print(f"   âœ… Generated {duration:.2f}s audio")
                
                # ThÃªm silence tháº­t vÃ o sau (trá»« Ä‘oáº¡n cuá»‘i)
                if i < len(chunks) - 1:
                    silence = create_silence(silence_duration, sample_rate)
                    audio_segments.append(silence)
                    print(f"   â¸ï¸  Added {silence_duration}s real silence")
                
            except Exception as e:
                print(f"   âŒ Error processing chunk {i+1}: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # GhÃ©p táº¥t cáº£ audio láº¡i
        if not audio_segments:
            raise gr.Error("No audio generated. Please check your text and reference audio.")
        
        final_wave = np.concatenate(audio_segments)
        final_duration = len(final_wave) / sample_rate
        
        print(f"\nâœ… Audio generation complete!")
        print(f"   Total duration: {final_duration:.2f}s")
        print(f"   Segments: {len(chunks)} paragraphs")
        print(f"{'='*60}\n")
        
        # Táº¡o spectrogram
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            plt.figure(figsize=(12, 4))
            plt.specgram(final_wave, Fs=sample_rate, cmap='viridis')
            plt.xlabel('Time (s)')
            plt.ylabel('Frequency (Hz)')
            plt.title(f'Audio Spectrogram ({final_duration:.1f}s)')
            plt.colorbar(format='%+2.0f dB')
            plt.tight_layout()
            plt.savefig(spectrogram_path)
            plt.close()

        return (sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤ F5-TTS: Vietnamese Text-to-Speech (Hybrid Version)
    ### Model trained with ~1000 hours of data on RTX 3090 GPU
    
    **âœ¨ BEST OF BOTH WORLDS:**
    - ğŸ¯ **No skipped words** (processes entire paragraphs like Code 1)
    - â¸ï¸ **Natural pauses** (real silence between paragraphs like Code 2)
    - ğŸŒ **Reads foreign words** (preserves original text structure)
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ğŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ğŸ“ Text to Generate", 
            placeholder="""Enter text with paragraphs separated by blank lines...

Example:
Háº¯n lÃºc nÃ y Ä‘ang ngá»“i trÃªn boong tÃ u. Máº¯t nhÃ¬n ra biá»ƒn xa.

"Toa láº§n nÃ y trá»Ÿ vá» nhÃ  chÆ¡i Ä‘Æ°á»£c bao lÃ¢u?"

NgÆ°á»i há»i lÃ  má»™t ngÆ°á»i báº¡n tÃ¬nh cá» gáº·p.

"Meci beaucoup!" Háº¯n Ä‘Ã¡p.
""", 
            lines=10
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="âš¡ Speed"
        )
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Controls real silence + pause markers"
        )
    
    btn_synthesize = gr.Button("ğŸ”¥ Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="ğŸ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ğŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ğŸ’¡ How HYBRID Processing Works:
    
    | Stage | Description |
    |-------|-------------|
    | **1. Split by Paragraph** | Text divided by `\\n\\n` (preserves full context) |
    | **2. Add Pause Markers** | Dots (`...`) inserted after sentences (smooth rhythm) |
    | **3. Process Each Paragraph** | Entire paragraph generated at once (no word skipping) |
    | **4. Add Real Silence** | Actual silent gaps between paragraphs (clean pauses) |
    | **5. Concatenate** | All segments combined into final audio |
    
    ### ğŸ¯ Why This Works Better:
    
    **Problem with Code 1:**
    - âŒ Pause markers alone don't create enough separation
    - âŒ Model interprets dots inconsistently
    
    **Problem with Code 2:**
    - âŒ Splits into small sentences â†’ words get lost
    - âŒ Over-normalization breaks foreign words
    - âŒ Merging logic is complex and error-prone
    
    **This Hybrid Solution:**
    - âœ… Processes **large chunks** (paragraph-level) â†’ no word loss
    - âœ… Uses **pause markers** for rhythm within paragraphs
    - âœ… Adds **real silence** between paragraphs for clear separation
    - âœ… **Foreign words preserved** (e.g., "Meci beaucoup!" works!)
    
    ### ğŸ“– Pause Levels:
    
    | Level | Marker | Silence | Best For |
    |-------|--------|---------|----------|
    | **Short** | `...` | 0.3s | Fast reading, news |
    | **Medium** | `.....` | 0.6s | Natural storytelling â­ |
    | **Long** | `.......` | 1.0s | Dramatic audiobooks |
    
    *Note: Dialogue automatically gets 50% shorter pauses*
    
    ### ğŸ“ Usage Tips:
    1. **Separate major sections** with double line breaks (`\\n\\n`)
    2. **Quote dialogue** normally: `"Hello," she said.`
    3. **Foreign words stay intact**: "Merci", "Thank you", "Danke"
    4. **Short sentences** are kept together (not split!)
    5. **Experiment** with pause levels to find your preference
    
    ### ğŸ¬ Example Processing:
    
    **Input:**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. Máº¯t nhÃ¬n biá»ƒn.
    
    "Merci beaucoup!"
    
    Há» gáº·p nhau á»Ÿ Paris.
    ```
    
    **Step 1 - Add Markers (Medium):**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. ..... Máº¯t nhÃ¬n biá»ƒn. .....
    
    "Merci beaucoup!" ...
    
    Há» gáº·p nhau á»Ÿ Paris. .....
    ```
    
    **Step 2 - Generate + Silence:**
    ```
    [Audio 1: "Háº¯n ngá»“i...biá»ƒn"] â†’ [0.6s silence]
    [Audio 2: "Merci beaucoup"] â†’ [0.3s silence]  
    [Audio 3: "Há» gáº·p...Paris"]
    ```
    
    **Result:** ğŸµ Complete, natural audio with proper pauses!
    
    ### âœ… Advantages Over Previous Versions:
    
    | Feature | Code 1 | Code 2 | Hybrid |
    |---------|--------|--------|--------|
    | No word skipping | âœ… | âŒ | âœ… |
    | Real silence pauses | âŒ | âœ… | âœ… |
    | Foreign words work | âœ… | âŒ | âœ… |
    | Processing speed | Fast | Slow | Medium |
    | Pause quality | Fair | Great | Excellent |
    """)
    
    with gr.Accordion("â— Known Limitations", open=False):
        gr.Markdown("""
        1. **Numbers**: Dates and phone numbers may not be perfect
        2. **Reference Audio**: Must be clear with minimal background noise
        3. **Very Long Text**: >500 words may take longer to process
        4. **Pause Timing**: First/last sentences might have slight timing differences
        5. **Model Artifacts**: Occasional clicks between segments (rare)
        
        ### ğŸ”§ Troubleshooting:
        - **Pauses too short?** â†’ Try "Long" level
        - **Pauses too long?** â†’ Try "Short" level  
        - **Word skipped?** â†’ Check if it's in a new paragraph (should work now!)
        - **Foreign word mispronounced?** â†’ This is a model limitation (but text is preserved)
        """)

    # Connect button to function
    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

# Launch with public link
demo.queue().launch(share=True)
