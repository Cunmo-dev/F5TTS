import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def post_process(text, silence_duration=0.3):
    """
    X·ª≠ l√Ω vƒÉn b·∫£n v·ªõi c√°c quy t·∫Øc:
    1. Thay th·∫ø t·∫•t c·∫£ d·∫•u ph·∫©y b·∫±ng d·∫•u ch·∫•m ƒë·ªÉ m·ªói c√¢u ng·∫Øn ƒë·ªÅu ƒë·ªôc l·∫≠p
    2. C√¢u trong d·∫•u ngo·∫∑c k√©p "" ƒë∆∞·ª£c coi l√† c√¢u ri√™ng bi·ªát
    3. Th√™m d·∫•u ch·∫•m tr∆∞·ªõc d·∫•u ngo·∫∑c k√©p m·ªü
    4. Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát trong d·∫•u ngo·∫∑c k√©p
    5. N·∫øu k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü cu·ªëi c√¢u trong ngo·∫∑c k√©p, thay b·∫±ng d·∫•u ch·∫•m
    6. Lo·∫°i b·ªè d·∫•u ph·∫©y/ch·∫•m tr√πng l·∫∑p trong ngo·∫∑c k√©p
    7. X·ª≠ l√Ω c√¢u ngo√†i d·∫•u ngo·∫∑c k√©p: lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát cu·ªëi c√¢u v√† th√™m d·∫•u ch·∫•m
    8. Th√™m kho·∫£ng l·∫∑ng gi·ªØa c√°c c√¢u b·∫±ng d·∫•u ch·∫•m (ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c)
    """
    
    # ƒê√°nh d·∫•u c√°c ƒëo·∫°n text trong d·∫•u ngo·∫∑c k√©p ƒë·ªÉ tr√°nh x·ª≠ l√Ω nh·∫ßm
    quoted_sections = []
    placeholder_pattern = "<<<QUOTED_{}>>>"
    
    def save_quoted_text(match):
        index = len(quoted_sections)
        quoted_sections.append(match.group(0))
        return placeholder_pattern.format(index)
    
    # T·∫°m th·ªùi thay th·∫ø c√°c ƒëo·∫°n text trong ngo·∫∑c k√©p b·∫±ng placeholder
    text = re.sub(r'"[^"]*"', save_quoted_text, text)
    
    # X·ª≠ l√Ω text ngo√†i d·∫•u ngo·∫∑c k√©p
    # T√°ch th√†nh c√°c ph·∫ßn d·ª±a tr√™n placeholder
    parts = re.split(r'(<<<QUOTED_\d+>>>)', text)
    
    processed_parts = []
    special_chars_pattern = r'[!@#$%^&*()_+=\[\]{};:\\|<>/?~`"\']'
    
    for part in parts:
        if part.startswith('<<<QUOTED_') and part.endswith('>>>'):
            # ƒê√¢y l√† placeholder, gi·ªØ nguy√™n
            processed_parts.append(part)
        else:
            # X·ª≠ l√Ω text ngo√†i ngo·∫∑c k√©p
            if part.strip():
                # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü cu·ªëi c√¢u
                part = part.rstrip()
                if part:
                    # Lo·∫°i b·ªè t·∫•t c·∫£ k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü cu·ªëi (kh√¥ng bao g·ªìm d·∫•u ch·∫•m)
                    while part and re.search(special_chars_pattern + r'$', part):
                        part = re.sub(special_chars_pattern + r'$', '', part).rstrip()
                    
                    # Th√™m d·∫•u ch·∫•m n·∫øu ch∆∞a c√≥
                    if part and not part.endswith('.'):
                        part += '.'
            
            processed_parts.append(part)
    
    text = ''.join(processed_parts)
    
    # X·ª≠ l√Ω c√°c ƒëo·∫°n text trong d·∫•u ngo·∫∑c k√©p
    def process_quoted_text(quoted_with_marks):
        # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p ƒë·ªÉ x·ª≠ l√Ω n·ªôi dung
        quoted = quoted_with_marks.strip('"')
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát (gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë, kho·∫£ng tr·∫Øng, d·∫•u ph·∫©y v√† d·∫•u ch·∫•m)
        special_chars_pattern = r'[!@#$%^&*()_+=\[\]{};:\\|<>/?~`]'
        quoted = re.sub(special_chars_pattern, '', quoted)
        
        # Lo·∫°i b·ªè d·∫•u ph·∫©y v√† d·∫•u ch·∫•m tr√πng l·∫∑p (ch·ªâ gi·ªØ 1 d·∫•u)
        quoted = re.sub(r'\.{2,}', '.', quoted)  # Nhi·ªÅu d·∫•u ch·∫•m -> 1 d·∫•u ch·∫•m
        quoted = re.sub(r',{2,}', ',', quoted)   # Nhi·ªÅu d·∫•u ph·∫©y -> 1 d·∫•u ph·∫©y
        quoted = re.sub(r'[,\s]+\.', '.', quoted)  # D·∫•u ph·∫©y + d·∫•u ch·∫•m -> d·∫•u ch·∫•m
        quoted = re.sub(r'\.[,\s]+', '. ', quoted)  # D·∫•u ch·∫•m + d·∫•u ph·∫©y -> d·∫•u ch·∫•m
        
        # X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü cu·ªëi c√¢u trong ngo·∫∑c k√©p
        quoted = quoted.strip()
        
        # N·∫øu c√¢u kh√¥ng k·∫øt th√∫c b·∫±ng d·∫•u ch·∫•m, th√™m d·∫•u ch·∫•m
        if quoted and not quoted.endswith('.'):
            # Lo·∫°i b·ªè d·∫•u ph·∫©y cu·ªëi c√πng n·∫øu c√≥
            if quoted.endswith(','):
                quoted = quoted[:-1].strip()
            quoted += '.'
        
        # Tr·∫£ v·ªÅ v·ªõi d·∫•u ch·∫•m tr∆∞·ªõc ngo·∫∑c k√©p m·ªü
        return '. "' + quoted + '"'
    
    # Kh√¥i ph·ª•c c√°c ƒëo·∫°n text trong ngo·∫∑c k√©p v√† x·ª≠ l√Ω ch√∫ng
    for i, quoted_section in enumerate(quoted_sections):
        placeholder = placeholder_pattern.format(i)
        processed_quoted = process_quoted_text(quoted_section)
        text = text.replace(placeholder, processed_quoted)
    
    # X·ª≠ l√Ω c√°c d·∫•u ch·∫•m tr√πng l·∫∑p
    text = " " + text + " "
    text = text.replace(" . . ", " . ")
    text = " " + text + " "
    text = text.replace(" .. ", " . ")
    text = " " + text + " "
    # Lo·∫°i b·ªè pattern ". ." nhi·ªÅu l·∫ßn
    while " . . " in text:
        text = text.replace(" . . ", " . ")
    
    # Lo·∫°i b·ªè d·∫•u ch·∫•m th·ª´a ·ªü ƒë·∫ßu c√¢u (n·∫øu c√≥)
    text = re.sub(r'^\.\s+', '', text.strip())
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = " ".join(text.split())
    
    # ===== TH√äM KHO·∫¢NG L·∫∂NG GI·ªÆA C√ÅC C√ÇU =====
    # T√°ch c√°c c√¢u theo d·∫•u ch·∫•m
    sentences = text.split('.')
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if silence_duration > 0 and len(sentences) > 0:
        # T√≠nh s·ªë d·∫•u ch·∫•m ƒë·ªÉ t·∫°o kho·∫£ng l·∫∑ng (m·ªói 0.1s = 1 d·∫•u ch·∫•m)
        num_dots = int(silence_duration * 10)
        silence_marker = "." * num_dots
        
        # N·ªëi c√°c c√¢u l·∫°i v·ªõi silence marker
        text = silence_marker.join(sentences) + "."
    else:
        # Kh√¥ng c√≥ kho·∫£ng l·∫∑ng, ch·ªâ n·ªëi b·∫±ng d·∫•u ch·∫•m ƒë∆°n
        text = ". ".join(sentences) + "."
    
    return text

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path = str(cached_path("hf://datasets/hynt/ZipVoice-Vietnamese-2500h-Features/epoch-11.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)
# ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt"))

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, silence_duration: float = 0.3, request: gr.Request = None):

    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        
        # X·ª≠ l√Ω text v·ªõi silence duration
        processed_text = post_process(TTSnorm(gen_text), silence_duration).lower()
        
        final_wave, final_sample_rate, spectrogram = infer_process(
            ref_audio, ref_text.lower(), processed_text, model, vocoder, speed=speed
        )
        
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        return (final_sample_rate, final_wave), spectrogram_path
    except Exception as e:
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # üé§ F5-TTS: Vietnamese Text-to-Speech Synthesis
    # The model was trained with approximately 1000 hours of data on a RTX 3090 GPU
    Enter text and upload a sample voice to generate natural speech.
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="üîä Sample Voice", type="filepath")
        gen_text = gr.Textbox(label="üìù Text", placeholder="Enter the text to generate voice...", lines=3)
    
    with gr.Row():
        speed = gr.Slider(0.3, 2.0, value=1.0, step=0.1, label="‚ö° Speed")
        silence_duration = gr.Slider(0.0, 2.0, value=0.3, step=0.1, label="üîá Silence Between Sentences (seconds)")
    
    btn_synthesize = gr.Button("üî• Generate Voice")
    
    with gr.Row():
        output_audio = gr.Audio(label="üéß Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="üìä Spectrogram")
    
    model_limitations = gr.Textbox(
        value="""1. This model may not perform well with numerical characters, dates, special characters, etc. => A text normalization module is needed.
2. The rhythm of some generated audios may be inconsistent or choppy => It is recommended to select clearly pronounced sample audios with minimal pauses for better synthesis quality.
3. Default, reference audio text uses the pho-whisper-medium model, which may not always accurately recognize Vietnamese, resulting in poor voice synthesis quality.
4. Inference with overly long paragraphs may produce poor results.
5. Sentences are joined by periods (.) - use silence slider to adjust pause duration between sentences.""", 
        label="‚ùó Model Limitations",
        lines=5,
        interactive=False
    )

    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, silence_duration], 
        outputs=[output_audio, output_spectrogram]
    )

# Run Gradio with share=True to get a gradio.live link
demo.queue().launch(share=True)
