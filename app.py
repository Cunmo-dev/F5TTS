import os
os.environ["MPLBACKEND"] = "Agg"

import spaces
from huggingface_hub import login
import gradio as gr
from cached_path import cached_path
import tempfile
from vinorm import TTSnorm
import re

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    preprocess_ref_audio_text,
    load_vocoder,
    load_model,
    infer_process,
    save_spectrogram,
)

# Retrieve token from secrets
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# Log in to Hugging Face
if hf_token:
    login(token=hf_token)

def add_natural_pauses(text, pause_level="Medium"):
    """
    ThÃªm kÃ½ hiá»‡u Ä‘áº·c biá»‡t Ä‘á»ƒ táº¡o khoáº£ng dá»«ng tá»± nhiÃªn.
    Sá»­ dá»¥ng dáº¥u cháº¥m láº·p (...) thay vÃ¬ dáº¥u pháº©y Ä‘á»ƒ trÃ¡nh Ã¢m láº¡.
    """
    # Cáº¥u hÃ¬nh pause báº±ng dáº¥u cháº¥m láº·p
    pause_configs = {
        "Short": (".....", "...."),         # Paragraph: 3 dots, Dialogue: 2 dots
        "Medium": (".......", "....."),     # Paragraph: 5 dots, Dialogue: 3 dots
        "Long": (".........", "......."),   # Paragraph: 7 dots, Dialogue: 5 dots
    }
    
    pause_paragraph, pause_dialogue = pause_configs.get(pause_level, (".....", "..."))
    
    print(f"\nğŸ›ï¸ Pause markers: Paragraph='{pause_paragraph}', Dialogue='{pause_dialogue}'")
    
    # TÃ¡ch theo dÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n biá»‡t Ä‘oáº¡n vÄƒn
    paragraphs = text.split('\n\n')
    processed_paragraphs = []
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # Gá»™p cÃ¡c dÃ²ng trong cÃ¹ng Ä‘oáº¡n
        lines = para.split('\n')
        combined_text = ' '.join(line.strip() for line in lines if line.strip())
        
        # Kiá»ƒm tra há»™i thoáº¡i (cÃ³ dáº¥u ngoáº·c)
        has_quotes = '"' in combined_text or '"' in combined_text or '"' in combined_text
        is_dialogue = has_quotes
        
        pause_marker = pause_dialogue if is_dialogue else pause_paragraph
        
        # Thay tháº¿ dáº¥u cÃ¢u cuá»‘i báº±ng dáº¥u cÃ¢u + pause marker
        # VÃ­ dá»¥: "Xin chÃ o." -> "Xin chÃ o. ....."
        combined_text = re.sub(r'([.!?])(\s|$)', r'\1 ' + pause_marker + r'\2', combined_text)
        
        processed_paragraphs.append(combined_text)
    
    result = '\n\n'.join(processed_paragraphs)
    
    print(f"\nğŸ“ Processed text preview:")
    print(result[:300] + "..." if len(result) > 300 else result)
    
    return result

def post_process(text):
    """LÃ m sáº¡ch vÄƒn báº£n - GIá»® Láº I dáº¥u cháº¥m láº·p Ä‘á»ƒ táº¡o pause."""
    text = " " + text + " "
    # KHÃ”NG gá»™p dáº¥u cháº¥m láº·p - Ä‘á»ƒ model tá»± xá»­ lÃ½
    text = text.replace('"', "")
    text = text.replace('"', "")
    text = text.replace('"', "")
    # Chá»‰ gá»™p dáº¥u pháº©y dÆ° thá»«a
    text = re.sub(r',+', ',', text)
    text = text.replace(" , ", " ")
    return " ".join(text.split())

# Load models
vocoder = load_vocoder()
model = load_model(
    DiT,
    dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4),
    ckpt_path=str(cached_path("hf://thanhcong190693/F5TTSVN/model_last.pt")),
    vocab_file=str(cached_path("hf://thanhcong190693/F5TTSVN/config.json")),
)

@spaces.GPU
def infer_tts(ref_audio_orig: str, gen_text: str, speed: float = 1.0, 
              pause_level: str = "Medium", request: gr.Request = None):
    """
    TTS inference - xá»­ lÃ½ toÃ n bá»™ vÄƒn báº£n má»™t láº§n vá»›i pause markers.
    """
    if not ref_audio_orig:
        raise gr.Error("Please upload a sample audio file.")
    if not gen_text.strip():
        raise gr.Error("Please enter the text content to generate voice.")
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ¤ Starting TTS generation")
        print(f"{'='*60}")
        
        # ThÃªm pause markers vÃ o vÄƒn báº£n
        processed_text = add_natural_pauses(gen_text, pause_level)
        
        print(f"\nğŸ“Š Stats:")
        print(f"   Original length: {len(gen_text)} chars")
        print(f"   Processed length: {len(processed_text)} chars")
        print(f"   Word count: {len(processed_text.split())} words")
        
        # Preprocess reference audio
        print(f"\nğŸ”„ Processing reference audio...")
        ref_audio, ref_text = preprocess_ref_audio_text(ref_audio_orig, "")
        print(f"   Reference text: {ref_text[:100]}...")
        
        # Chuáº©n hÃ³a vÄƒn báº£n (giá»¯ láº¡i dáº¥u cháº¥m láº·p)
        normalized_text = post_process(TTSnorm(processed_text)).lower()
        
        print(f"\nğŸ“ Normalized text preview:")
        print(f"   {normalized_text[:200]}...")
        
        # Táº¡o audio - Xá»¬ LÃ TOÃ€N Bá»˜ Má»˜T Láº¦N
        print(f"\nğŸµ Generating audio...")
        final_wave, final_sample_rate, spectrogram = infer_process(
            ref_audio, 
            ref_text.lower(), 
            normalized_text, 
            model, 
            vocoder, 
            speed=speed
        )
        
        duration = len(final_wave) / final_sample_rate
        print(f"\nâœ… Audio generated successfully!")
        print(f"   Duration: {duration:.2f}s")
        print(f"   Sample rate: {final_sample_rate}Hz")
        print(f"{'='*60}\n")
        
        # LÆ°u spectrogram
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_spectrogram:
            spectrogram_path = tmp_spectrogram.name
            save_spectrogram(spectrogram, spectrogram_path)

        return (final_sample_rate, final_wave), spectrogram_path
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Error generating voice: {e}")

# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤ F5-TTS: Vietnamese Text-to-Speech Synthesis
    ### Model trained with ~1000 hours of data on RTX 3090 GPU
    
    Enter text and upload a sample voice to generate natural speech with **intelligent pause control**.
    
    âœ¨ **Smart Pause Feature**: Automatically adds natural pauses using special markers!
    """)
    
    with gr.Row():
        ref_audio = gr.Audio(label="ğŸ”Š Sample Voice", type="filepath")
        gen_text = gr.Textbox(
            label="ğŸ“ Text to Generate", 
            placeholder="""Enter text with paragraphs separated by blank lines...

Example:
Háº¯n lÃºc nÃ y Ä‘ang ngá»“i trÃªn boong tÃ u. Máº¯t nhÃ¬n ra biá»ƒn xa.

"Toa láº§n nÃ y trá»Ÿ vá» nhÃ  chÆ¡i Ä‘Æ°á»£c bao lÃ¢u?"

NgÆ°á»i há»i lÃ  má»™t ngÆ°á»i báº¡n tÃ¬nh cá» gáº·p.

"Meci beaucoup!"
""", 
            lines=10
        )
    
    with gr.Row():
        speed = gr.Slider(
            minimum=0.3, 
            maximum=2.0, 
            value=1.0, 
            step=0.1, 
            label="âš¡ Speed"
        )
        pause_level = gr.Radio(
            choices=["Short", "Medium", "Long"],
            value="Medium",
            label="â¸ï¸ Pause Duration",
            info="Controls natural pauses after sentences"
        )
    
    btn_synthesize = gr.Button("ğŸ”¥ Generate Voice", variant="primary", size="lg")
    
    with gr.Row():
        output_audio = gr.Audio(label="ğŸ§ Generated Audio", type="numpy")
        output_spectrogram = gr.Image(label="ğŸ“Š Spectrogram")
    
    gr.Markdown("""
    ### ğŸ’¡ How It Works:
    
    | Feature | Description |
    |---------|-------------|
    | **Single-Pass Processing** | Entire text processed at once (no sentence splitting!) |
    | **Pause Markers** | Uses dot sequences (`...`) to create natural pauses |
    | **Automatic Detection** | Distinguishes narrative vs dialogue paragraphs |
    | **No Weird Sounds** | Dots create smoother pauses than commas |
    | **Three Levels** | Short (quick), Medium (natural), Long (dramatic) |
    
    ### ğŸ“– Pause Levels:
    - **Short**: Quick pauses (2-3 dots) - best for news, fast reading
    - **Medium**: Natural pauses (3-5 dots) - recommended for stories
    - **Long**: Dramatic pauses (5-7 dots) - ideal for audiobooks
    
    ### ğŸ¯ Example Processing:
    
    **Input:**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. Máº¯t nhÃ¬n ra biá»ƒn.
    
    "Xin chÃ o!"
    ```
    
    **After Pause Injection (Medium):**
    ```
    Háº¯n ngá»“i trÃªn tÃ u. ..... Máº¯t nhÃ¬n ra biá»ƒn. .....
    
    "Xin chÃ o!" ...
    ```
    
    The model reads the dots as natural pauses, creating rhythm without weird sounds!
    
    ### âœ… Advantages:
    - âœ¨ **No skipped sentences** - all text is read including "Meci beaucoup!"
    - ğŸµ **Natural rhythm** - dots create smoother pauses than commas
    - âš¡ **Fast processing** - single pass through the model
    - ğŸ¯ **Consistent quality** - same as original code but with better pauses
    
    ### ğŸ“ Usage Tips:
    - Separate major sections with **double line breaks** (`\\n\\n`)
    - Quote dialogue: `"Hello," she said.`
    - Short sentences are automatically handled (no skipping!)
    - Experiment with pause levels to find what sounds best
    """)
    
    with gr.Accordion("â— Model Limitations", open=False):
        gr.Markdown("""
        1. **Numbers & Special Characters**: May not handle dates, phone numbers perfectly
        2. **Audio Quality**: Use clear reference audio with minimal background noise
        3. **Reference Text**: Auto-transcribed using Whisper (may have errors)
        4. **Very Long Text**: Texts over 1000 words may produce inconsistent results
        5. **Foreign Words**: May not pronounce non-Vietnamese words correctly
        
        ### ğŸ”§ Troubleshooting:
        - If pauses sound unnatural, try a different pause level
        - If you hear weird sounds, use "Short" pause level
        - For very long texts, consider splitting into multiple generations
        """)

    # Connect button to function
    btn_synthesize.click(
        infer_tts, 
        inputs=[ref_audio, gen_text, speed, pause_level], 
        outputs=[output_audio, output_spectrogram]
    )

# Launch with public link
demo.queue().launch(share=True)
